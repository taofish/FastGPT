<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>FastGPT</title><link>https://doc.tryfastgpt.ai/</link><description>Recent content on FastGPT</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><atom:link href="https://doc.tryfastgpt.ai/index.xml" rel="self" type="application/rss+xml"/><item><title>快速了解 FastGPT</title><link>https://doc.tryfastgpt.ai/docs/intro/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/intro/</guid><description>FastGPT 是一个基于 LLM 大语言模型的知识库问答系统，提供开箱即用的数据处理、模型调用等能力。同时可以通过 Flow 可视化进行工作流编排，从而实现复杂的问答场景！
🤖
FastGPT 在线使用：https://fastgpt.in
FastGPT 能力 link1. 专属 AI 客服 link通过导入文档或已有问答对进行训练，让 AI 模型能根据你的文档以交互式对话方式回答问题。
2. 简单易用的可视化界面 linkFastGPT 采用直观的可视化界面设计，为各种应用场景提供了丰富实用的功能。通过简洁易懂的操作步骤，可以轻松完成 AI 客服的创建和训练流程。
3. 自动数据预处理 link提供手动输入、直接分段、LLM 自动处理和 CSV 等多种数据导入途径，其中“直接分段”支持通过 PDF、WORD、Markdown 和 CSV 文档内容作为上下文。FastGPT 会自动对文本数据进行预处理、向量化和 QA 分割，节省手动训练时间，提升效能。
4. 工作流编排 link基于 Flow 模块的工作流编排，可以帮助你设计更加复杂的问答流程。例如查询数据库、查询库存、预约实验室等。
5. 强大的 API 集成 linkFastGPT 对外的 API 接口对齐了 OpenAI 官方接口，可以直接接入现有的 GPT 应用，也可以轻松集成到企业微信、公众号、飞书等平台。
FastGPT 特点 link 项目开源
FastGPT 遵循附加条件 Apache License 2.0 开源协议，你可以 Fork 之后进行二次开发和发布。FastGPT 社区版将保留核心功能，商业版仅在社区版基础上使用 API 的形式进行扩展，不影响学习使用。
独特的 QA 结构</description></item><item><title>快速上手</title><link>https://doc.tryfastgpt.ai/docs/course/quick-start/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/course/quick-start/</guid><description>更多使用技巧，查看视屏教程
知识库 link开始前，请准备一份测试电子文档，WORD，PDF，TXT，excel，markdown 都可以，比如公司休假制度，不涉密的销售说辞，产品知识等等。
这里使用 FastGPT 中文 README 文件为例。
首先我们需要创建一个知识库。
知识库创建完之后我们需要上传一点内容。
上传内容这里有四种模式：
手动输入：手动输入问答对，是最精准的数据 QA 拆分：选择文本文件，让AI自动生成问答对 直接分段：选择文本文件，直接将其按分段进行处理 CSV 导入：批量导入问答对 这里，我们选择 QA 拆分，让 AI 自动生成问答，若问答质量不高，可以后期手动修改。
点击上传后我们需要等待数据处理完成，等到我们上传的文件状态为可用。
应用 link点击「应用」按钮来新建一个应用，这里有四个模板，我们选择「知识库 + 对话引导」。
应用创建后来再应用详情页找到「知识库」模块，把我们刚刚创建的知识库添加进去。
添加完知识库后记得点击「保存并预览」，这样我们的应用就和知识库关联起来了。
然后我们就可以愉快的开始聊天啦。</description></item><item><title>AI 相关参数配置说明</title><link>https://doc.tryfastgpt.ai/docs/course/ai_settings/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/course/ai_settings/</guid><description>在 FastGPT 的 AI 对话模块中，有一个 AI 高级配置，里面包含了 AI 模型的参数配置，本文详细介绍这些配置的含义。
返回AI内容（高级编排特有） link这是一个开关，打开的时候，当 AI 对话模块运行时，会将其输出的内容返回到浏览器（API响应）；如果关闭，AI 输出的内容不会返回到浏览器，但是生成的内容仍可以通过【AI回复】进行输出。你可以将【AI回复】连接到其他模块中。
最大上下文 link代表模型最多容纳的文字数量。
函数调用 link支持函数调用的模型，在使用工具时更加准确。
温度 link越低回答越严谨，少废话（实测下来，感觉差别不大）
回复上限 link最大回复 token 数量。注意，是回复的Tokens！不是上下文 tokens。
系统提示词 link被放置在上下文数组的最前面，role 为 system，用于引导模型。
引用模板 &amp;amp; 引用提示词 link这两个参数与知识库问答场景相关，可以控制知识库相关的提示词。
AI 对话消息组成 link想使用明白这两个变量，首先要了解传递传递给 AI 模型的消息格式。它是一个数组，FastGPT 中这个数组的组成形式为：
[ 内置提示词（config.json 配置，一般为空） 系统提示词 （用户输入的提示词） 历史记录 问题（由引用提示词、引用模板和用户问题组成） ] 🍅
Tips: 可以通过点击上下文按键查看完整的上下文组成，便于调试。
引用模板和提示词设计 link简易模式已移除该功能，仅在工作流中可配置，可点击工作流中AI对话节点内，知识库引用旁边的setting icon进行配置。随着模型的增强，这部分功能将逐步弱化。
引用模板和引用提示词通常是成对出现，引用提示词依赖引用模板。
FastGPT 知识库采用 QA 对(不一定都是问答格式，仅代表两个变量)的格式存储，在转义成字符串时候会根据引用模板来进行格式化。知识库包含多个可用变量： q, a, sourceId（数据的ID）, index(第n个数据), source(数据的集合名、文件名)，score(距离得分，0-1) 可以通过 {{q}} {{a}} {{sourceId}} {{index}} {{source}} {{score}} 按需引入。下面一个模板例子：</description></item><item><title>Web 站点同步</title><link>https://doc.tryfastgpt.ai/docs/course/websync/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/course/websync/</guid><description>该功能目前仅向商业版用户开放。
什么是 Web 站点同步 linkWeb 站点同步利用爬虫的技术，可以通过一个入口网站，自动捕获同域名下的所有网站，目前最多支持200个子页面。出于合规与安全角度，FastGPT 仅支持静态站点的爬取，主要用于各个文档站点快速构建知识库。
Tips: 国内的媒体站点基本不可用，公众号、csdn、知乎等。可以通过终端发送curl请求检测是否为静态站点，例如：
curl https://doc.fastgpt.in/docs/intro/ 如何使用 link1. 新建知识库，选择 Web 站点同步 link 2. 点击配置站点信息 link 3. 填写网址和选择器 link 好了， 现在点击开始同步，静等系统自动抓取网站信息即可。
创建应用，绑定知识库 link 选择器如何使用 link选择器是 HTML CSS JS 的产物，你可以通过选择器来定位到你需要抓取的具体内容，而不是整个站点。使用方式为：
首先打开浏览器调试面板（通常是 F12，或者【右键 - 检查】） link 输入对应元素的选择器 link菜鸟教程 css 选择器，具体选择器的使用方式可以参考菜鸟教程。
上图中，我们选中了一个区域，对应的是div标签，它有 data-prismjs-copy, data-prismjs-copy-success, data-prismjs-copy-error 三个属性，这里我们用到一个就够。所以选择器是： div[data-prismjs-copy]
除了属性选择器，常见的还有类和ID选择器。例如：
上图 class 里的是类名（可能包含多个类名，都是空格隔开的，选择一个即可），选择器可以为：.docs-content
多选择器使用 link在开头的演示中，我们对 FastGPT 文档是使用了多选择器的方式来选择，通过逗号隔开了两个选择器。
我们希望选中上图两个标签中的内容，此时就需要两组选择器。一组是：.docs-content .mb-0.d-flex，含义是 docs-content 类下同时包含 mb-0和d-flex 两个类的子元素；
另一组是.docs-content div[data-prismjs-copy]，含义是docs-content 类下包含data-prismjs-copy属性的div元素。
把两组选择器用逗号隔开即可：.docs-content .mb-0.d-flex, .docs-content div[data-prismjs-copy]</description></item><item><title>知识库搜索方案和参数</title><link>https://doc.tryfastgpt.ai/docs/course/dataset_engine/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/course/dataset_engine/</guid><description>理解向量 linkFastGPT 采用了 RAG 中的 Embedding 方案构建知识库，要使用好 FastGPT 需要简单的理解Embedding向量是如何工作的及其特点。
人类的文字、图片、视频等媒介是无法直接被计算机理解的，要想让计算机理解两段文字是否有相似性、相关性，通常需要将它们转成计算机可以理解的语言，向量是其中的一种方式。
向量可以简单理解为一个数字数组，两个向量之间可以通过数学公式得出一个距离，距离越小代表两个向量的相似度越大。从而映射到文字、图片、视频等媒介上，可以用来判断两个媒介之间的相似度。向量搜索便是利用了这个原理。
而由于文字是有多种类型，并且拥有成千上万种组合方式，因此在转成向量进行相似度匹配时，很难保障其精确性。在向量方案构建的知识库中，通常使用topk召回的方式，也就是查找前k个最相似的内容，丢给大模型去做更进一步的语义判断、逻辑推理和归纳总结，从而实现知识库问答。因此，在知识库问答中，向量搜索的环节是最为重要的。
影响向量搜索精度的因素非常多，主要包括：向量模型的质量、数据的质量（长度，完整性，多样性）、检索器的精度（速度与精度之间的取舍）。与数据质量对应的就是检索词的质量。
检索器的精度比较容易解决，向量模型的训练略复杂，因此数据和检索词质量优化成了一个重要的环节。
提高向量搜索精度的方法 link 更好分词分段：当一段话的结构和语义是完整的，并且是单一的，精度也会提高。因此，许多系统都会优化分词器，尽可能的保障每组数据的完整性。 精简index的内容，减少向量内容的长度：当index的内容更少，更准确时，检索精度自然会提高。但与此同时，会牺牲一定的检索范围，适合答案较为严格的场景。 丰富index的数量，可以为同一个chunk内容增加多组index。 优化检索词：在实际使用过程中，用户的问题通常是模糊的或是缺失的，并不一定是完整清晰的问题。因此优化用户的问题（检索词）很大程度上也可以提高精度。 微调向量模型：由于市面上直接使用的向量模型都是通用型模型，在特定领域的检索精度并不高，因此微调向量模型可以很大程度上提高专业领域的检索效果。 FastGPT 构建知识库方案 link数据存储结构 link在 FastGPT 中，整个知识库由库、集合和数据 3 部分组成。集合可以简单理解为一个文件。一个库中可以包含多个集合，一个集合中可以包含多组数据。最小的搜索单位是库，也就是说，知识库搜索时，是对整个库进行搜索，而集合仅是为了对数据进行分类管理，与搜索效果无关。（起码目前还是）
向量存储结构 linkFastGPT 采用了PostgresSQL的PG Vector插件作为向量检索器，索引为HNSW。且PostgresSQL仅用于向量检索（该引擎可以替换成其它数据库），MongoDB用于其他数据的存取。
在MongoDB的dataset.datas表中，会存储向量原数据的信息，同时有一个indexes字段，会记录其对应的向量ID，这是一个数组，也就是说，一组向量可以对应多组数据。
在PostgresSQL的表中，设置一个vector字段用于存储向量。在检索时，会先召回向量，再根据向量的ID，去MongoDB中寻找原数据内容，如果对应了同一组原数据，则进行合并，向量得分取最高得分。
多向量的目的和使用方式 link在一组向量中，内容的长度和语义的丰富度通常是矛盾的，无法兼得。因此，FastGPT 采用了多向量映射的方式，将一组数据映射到多组向量中，从而保障数据的完整性和语义的丰富度。
你可以为一组较长的文本，添加多组向量，从而在检索时，只要其中一组向量被检索到，该数据也将被召回。
意味着，你可以通过标注数据块的方式，不断提高数据块的精度。
检索方案 link 通过问题优化实现指代消除和问题扩展，从而增加连续对话的检索能力以及语义丰富度。 通过Concat query来增加Rerank连续对话的时，排序的准确性。 通过RRF合并方式，综合多个渠道的检索效果。 通过Rerank来二次排序，提高精度。 搜索参数 link 搜索模式 link语义检索 link语义检索是通过向量距离，计算用户问题与知识库内容的距离，从而得出“相似度”，当然这并不是语文上的相似度，而是数学上的。
优点：
相近语义理解 跨多语言理解（例如输入中文问题匹配英文知识点） 多模态理解（文本，图片，音视频等） 缺点：
依赖模型训练效果 精度不稳定 受关键词和句子完整度影响 全文检索 link采用传统的全文检索方式。适合查找关键的主谓语等。
混合检索 link同时使用向量检索和全文检索，并通过 RRF 公式进行两个搜索结果合并，一般情况下搜索结果会更加丰富准确。
由于混合检索后的查找范围很大，并且无法直接进行相似度过滤，通常需要进行利用重排模型进行一次结果重新排序，并利用重排的得分进行过滤。
结果重排 link利用ReRank模型对搜索结果进行重排，绝大多数情况下，可以有效提高搜索结果的准确率。不过，重排模型与问题的完整度（主谓语齐全）有一些关系，通常会先走问题优化后再进行搜索-重排。重排后可以得到一个0-1的得分，代表着搜索内容与问题的相关度，该分数通常比向量的得分更加精确，可以根据得分进行过滤。
FastGPT 会使用 RRF 对重排结果、向量搜索结果、全文检索结果进行合并，得到最终的搜索结果。</description></item><item><title>外部文件知识库</title><link>https://doc.tryfastgpt.ai/docs/course/externalfile/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/course/externalfile/</guid><description>外部文件库是 FastGPT 商业版特有功能。它允许接入你现在的文件系统，无需将文件再导入一份到 FastGPT 中。
并且，阅读权限可以通过你的文件系统进行控制。
导入参数说明 link 外部预览地址：用于跳转你的文件阅读地址，会携带“文件阅读ID”进行访问。 文件访问URL：文件可访问的地址。 文件阅读ID：通常情况下，文件访问URL是临时的。如果希望永久可以访问，你需要使用该文件阅读ID，并配合上“外部预览地址”，跳转至新的阅读地址进行原文件访问。 文件名：默认会自动解析文件访问URL上的文件名。如果你手动填写，将会以手动填写的值为准。 点击查看API导入文档</description></item><item><title>对话问题引导</title><link>https://doc.tryfastgpt.ai/docs/course/chat_input_guide/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/course/chat_input_guide/</guid><description> 什么是自定义问题引导 link你可以为你的应用提前预设一些问题，用户在输入时，会根据输入的内容，动态搜索这些问题作为提示，从而引导用户更快的进行提问。
你可以直接在 FastGPT 中配置词库，或者提供自定义词库接口。
自定义词库接口 link需要保证这个接口可以被用户浏览器访问。
请求：
curl --location --request GET &amp;#39;http://localhost:3000/api/core/chat/inputGuide/query?appId=663c75302caf8315b1c00194&amp;amp;searchKey=你&amp;#39; 其中 appId 为应用ID，searchKey 为搜索关键字，最多是50个字符。
响应
{ &amp;#34;code&amp;#34;: 200, &amp;#34;statusText&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;message&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;data&amp;#34;: [ &amp;#34;是你&amp;#34;, &amp;#34;你是谁呀&amp;#34;, &amp;#34;你好好呀&amp;#34;, &amp;#34;你好呀&amp;#34;, &amp;#34;你是谁！&amp;#34;, &amp;#34;你好&amp;#34; ] } data是一个数组，包含了搜索到的问题，最多只需要返回5个问题。
参数说明：
appId - 应用ID searchKey - 搜索关键字</description></item><item><title>知识库集合标签</title><link>https://doc.tryfastgpt.ai/docs/course/collection_tags/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/course/collection_tags/</guid><description>知识库集合标签是 FastGPT 商业版特有功能。它允许你对知识库中的数据集合添加标签进行分类，更高效地管理知识库数据。
而进一步可以在问答中，搜索知识库时添加集合过滤，实现更精确的搜索。
标签基础操作说明 link在知识库详情页面，可以对标签进行管理，可执行的操作有
创建标签 修改标签名 删除标签 将一个标签赋给多个数据集合 给一个数据集合添加多个标签 也可以利用标签对数据集合进行筛选
知识库搜索-集合过滤说明 link利用标签可以在知识库搜索时，通过填写「集合过滤」这一栏来实现更精确的搜索，具体的填写示例如下
{ &amp;#34;tags&amp;#34;: { &amp;#34;$and&amp;#34;: [&amp;#34;标签 1&amp;#34;,&amp;#34;标签 2&amp;#34;], &amp;#34;$or&amp;#34;: [&amp;#34;有 $and 标签时，and 生效，or 不生效&amp;#34;] }, &amp;#34;createTime&amp;#34;: { &amp;#34;$gte&amp;#34;: &amp;#34;YYYY-MM-DD HH:mm 格式即可，集合的创建时间大于该时间&amp;#34;, &amp;#34;$lte&amp;#34;: &amp;#34;YYYY-MM-DD HH:mm 格式即可，集合的创建时间小于该时间,可和 $gte 共同使用&amp;#34; } } 在填写时有两个注意的点，
标签值可以为 string 类型的标签名，也可以为 null，而 null 代表着未设置标签的数据集合 标签过滤有 $and 和 $or 两种条件类型，在同时设置了 $and 和 $or 的情况下，只有 $and 会生效</description></item><item><title>文件输入功能介绍</title><link>https://doc.tryfastgpt.ai/docs/course/fileinput/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/course/fileinput/</guid><description>从 4.8.9 版本起，FastGPT 支持在简易模式和工作流中，配置用户上传文件、图片功能。下面先简单介绍下如何使用文件输入功能，最后是介绍下文件解析的工作原理。
简易模式中使用 link简易模式打开文件上传后，会使用工具调用模式，也就是由模型自行决策，是否需要读取文件内容。
可以找到左侧文件上传的配置项，点击其右侧的开启/关闭按键，即可打开配置弹窗。
随后，你的调试对话框中，就会出现一个文件选择的 icon，可以点击文件选择 icon，选择你需要上传的文件。
由于采用的是工具调用模式，所以在提问时候，可能需要加上适当的引导，让模型知道，你需要读取文档。
工作流中使用 link工作流中，可以在系统配置中，找到文件输入配置项，点击其右侧的开启/关闭按键，即可打开配置弹窗。
在工作流中，使用文件的方式很多，最简单的就是类似下图中，直接通过工具调用接入文档解析，实现和简易模式一样的效果。
也可以更简单点，强制每轮对话都携带上文档内容进行回答，这样就不需要调用两次 AI 才能读取文档内容了。
当然，你也可以在工作流中，对文档进行内容提取、内容分析等，然后将分析的结果传递给 HTTP 或者其他模块，从而实现文件处理的 SOP。不过目前版本，插件中并未支持文件处理，所以在构建 SOP 的话可能还是有一些麻烦。
文档解析工作原理 link不同于图片识别，LLM 模型目前没有支持直接解析文档的能力，所有的文档“理解”都是通过文档转文字后拼接 prompt 实现。这里通过几个 FAQ 来解释文档解析的工作原理，理解文档解析的原理，可以更好的在工作流中使用文档解析功能。
上传的文件如何存储在数据库中 linkFastGPT 的对话记录存储结构中，role=user 的消息，value 值会按以下结构存储：
type UserChatItemValueItemType = { type: &amp;#39;text&amp;#39; | &amp;#39;file&amp;#39; text?: { content: string; }; file?: { type: &amp;#39;img&amp;#39; | &amp;#39;doc&amp;#39; name?: string; url: string; }; }; 也就是说，上传的图片和文档，都会以 URL 的形式存储在库中，并不会存储解析后的文档内容。
图片如何处理 link文档解析节点不会处理图片，图片链接会被过滤，图片识别请直接使用支持图片识别的 LLM 模型。
文档解析节点如何工作 link文档解析依赖文档解析节点，这个节点会接收一个array&amp;lt;string&amp;gt;类型的输入，对应的是文件输入的 URL；输出的是一个string，对应的是文档解析后的内容。</description></item><item><title>接入飞书机器人教程</title><link>https://doc.tryfastgpt.ai/docs/course/feishu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/course/feishu/</guid><description>从 4.8.10 版本起，FastGPT 商业版支持直接接入飞书机器人，无需额外的 API。
1. 申请飞书应用 link开一个免费的测试企业更方便进行调试。
在飞书开放平台的开发者后台申请企业自建应用。 添加一个机器人应用。
2. 在 FastGPT 新建发布渠道 link在fastgpt中选择想要接入的应用，在 发布渠道 页面，新建一个接入飞书机器人的发布渠道，填写好基础信息。
3. 获取应用的 App ID, App Secret 两个凭证 link在飞书开放平台开发者后台，刚刚创建的企业自建应用中，找到 App ID 和 App Secret，填入 FastGPT 新建发布渠道的对话框里面。
填入两个参数到 FastGPT 配置弹窗中。
（可选）在飞书开放平台开发者后台，点击事件与回调 -&amp;gt; 加密策略 获取 Encrypt Key，并填入飞书机器人接入的对话框里面
Encrypt Key 用于加密飞书服务器与 FastGPT 之间通信。 建议如果使用 Https 协议，则不需要 Encrypt Key。如果使用 Http 协议通信，则建议使用 Encrypt Key Verification Token 默认生成的这个 Token 用于校验来源。但我们使用飞书官方推荐的另一种更为安全的校验方式，因此可以忽略这个配置项。
4. 配置回调地址 link新建好发布渠道后，点击请求地址，复制对应的请求地址。
在飞书控制台，点击左侧的 事件与回调 ，点击配置订阅方式旁边的编辑 icon，粘贴刚刚复制的请求地址到输入框中。
5. 配置机器人回调事件和权限 link 添加 接收消息 事件 在事件与回调页面，点击添加事件。</description></item><item><title>通过 API 访问应用</title><link>https://doc.tryfastgpt.ai/docs/course/openapi/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/course/openapi/</guid><description>在 FastGPT 中，你可以为每一个应用创建多个 API 密钥，用于访问应用的 API 接口。每个密钥仅能访问一个应用。完整的接口可以查看应用对话接口。
获取 API 密钥 link依次选择应用 -&amp;gt; 「API访问」，然后点击「API 密钥」来创建密钥。
warning 密钥需要自己保管好，一旦关闭就无法再复制密钥，只能创建新密钥再复制。
🍅
Tips: 安全起见，你可以设置一个额度或者过期时间，放置 key 被滥用。
替换三方应用的变量 link OPENAI_API_BASE_URL: https://api.fastgpt.in/api (改成自己部署的域名) OPENAI_API_KEY = 上一步获取到的密钥 ChatGPT Next Web 示例：
ChatGPT Web 示例：</description></item><item><title>接入微信公众号教程</title><link>https://doc.tryfastgpt.ai/docs/course/official_account/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/course/official_account/</guid><description>从 4.8.10 版本起，FastGPT 商业版支持直接接入微信公众号，无需额外的 API。
注意⚠️: 目前只支持通过验证的公众号（服务号和订阅号都可以）
1. 在 FastGPT 新建发布渠道 link在 FastGPT 中选择想要接入的应用，在 发布渠道 页面，新建一个接入微信公众号的发布渠道，填写好基础信息。
2. 登录微信公众平台，获取 AppID 、 Secret和Token link1. https://mp.weixin.qq.com 登录微信公众平台，选择您的公众号。 link只支持通过验证的公众号，未通过验证的公众号暂不支持。
开发者可以从这个链接申请微信公众号的测试号进行测试，测试号可以正常使用，但不能配置 AES Key
2. 把3个参数填入 FastGPT 配置弹窗中。 link 3. 在 IP 白名单中加入 FastGPT 的 IP link 私有部署的用户可自行查阅自己的 IP 地址。
海外版用户（fastgpt.in)可以填写下面的 IP 白名单：
34.87.20.17 35.247.161.35 34.87.51.146 34.87.110.152 35.247.163.68 34.126.163.205 34.87.20.189 34.87.102.86 35.240.227.100 35.198.192.104 34.143.149.171 34.87.152.33 34.124.237.188 35.197.149.75 34.87.44.74 34.124.189.116 34.87.79.202 34.87.173.252 34.143.240.160 34.87.180.104 34.142.157.52 4. 获取AES Key，选择加密方式 link 随机生成AESKey，填入 FastGPT 配置弹窗中。</description></item><item><title>高级编排介绍</title><link>https://doc.tryfastgpt.ai/docs/workflow/intro/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/workflow/intro/</guid><description>FastGPT 从 V4 版本开始采用新的交互方式来构建 AI 应用。使用了 Flow 节点编排（工作流）的方式来实现复杂工作流，提高可玩性和扩展性。但同时也提高了上手的门槛，有一定开发背景的用户使用起来会比较容易。
查看视频教程
什么是节点？ link在程序中，节点可以理解为一个个 Function 或者接口。可以理解为它就是一个步骤。将多个节点一个个拼接起来，即可一步步的去实现最终的 AI 输出。
如下图，这是一个最简单的 AI 对话。它由用流程开始和 AI 对话节点组成。
执行流程如下：
用户输入问题后，【流程开始】节点执行，用户问题被保存。 【AI 对话】节点执行，此节点有两个必填参数“聊天记录” “用户问题”，聊天记录的值是默认输入的6条，表示此模块上下文长度。用户问题选择的是【流程开始】模块中保存的用户问题。 【AI 对话】节点根据传入的聊天记录和用户问题，调用对话接口，从而实现回答。 节点分类 link从功能上，节点可以分为 2 类：
系统节点：用户引导（配置一些对话框信息）、用户问题（流程入口）。 功能节点：知识库搜索、AI 对话等剩余节点。（这些节点都有输入和输出，可以自由组合）。 节点的组成 link每个节点会包含 3 个核心部分：输入、输出和触发器。
AI模型、提示词、聊天记录、用户问题，知识库引用为输入，节点的输入可以是手动输入也可以是变量引用，变量引用的范围包括“全局变量”和之前任意一个节点的输出。 新的上下文和AI回复内容为输出，输出可以被之后任意节点变量引用。 节点的上下左右有四个“触发器”可以被用来连接，被连接的节点按顺序决定是否执行。 重点 - 工作流是如何运行的 linkFastGPT的工作流从【流程开始】节点开始执行，可以理解为从用户输入问题开始，没有固定的出口，是以节点运行结束作为出口，如果在一个轮调用中，所有节点都不再允许，则工作流结束。
下面我们来看下，工作流是如何运行的，以及每个节点何时被触发执行。
如上图所示节点会“被连接”也会“连接其他节点”，我们称“被连接”的那根线为前置线，“连接其他节点的线”为后置线。上图例子中【知识库搜索】模块左侧有一根前置线，右侧有一根后置线。而【AI对话】节点只有左侧一根前置线。
FastGPT工作流中的线有以下几种状态：
waiting：被连接的节点等待执行。 active：被连接的节点可以执行。 skip：被连接的节点不需要执行跳过。 节点执行的原则：
判断前置线中有没有状态为 waiting 的，如果有则等待。 判断前置线中状态有没有状态为 active 如果有则执行。 如果前置线中状态即没有 waiting 也没有 active 则认为此节点需要跳过。 节点执行完毕后，需要根据实际情况更改后置线的状态为active或skip并且更改前置线状态为waiting等待下一轮执行。 让我们看一下上面例子的执行过程：
【流程开始】节点执行完毕，更改后置线为active。 【知识库搜索】节点判断前置线状态为active开始执行，执行完毕后更改后置线状态为active 前置线状态为waiting。 【AI对话】节点判断前置线状态为active开始执行，流程执行结束。 如何连接节点 link 为了方便连接，FastGPT 每个节点的上下左右都有连接点，左和上是前置线连接点，右和下是后置线连接点。 可以点击连接线中间的 x 来删除连接线。 可以左键点击选中连接线 如何阅读？ link 建议从左往右阅读。 从 用户问题 节点开始。用户问题节点，代表的是用户发送了一段文本，触发任务开始。 关注【AI 对话】和【指定回复】节点，这两个节点是输出答案的地方。 FAQ link想合并多个输出结果怎么实现？ link 文本加工，可以对字符串进行合并。 知识库搜索合并，可以合并多个知识库搜索结果 其他结果，无法直接合并，可以考虑传入到HTTP节点中进行合并，使用[Laf](https://laf.</description></item><item><title>AI 对话</title><link>https://doc.tryfastgpt.ai/docs/workflow/modules/ai_chat/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/workflow/modules/ai_chat/</guid><description>特点 link 可重复添加 触发执行 核心模块 参数说明 linkAI模型 link可以通过 config.json 配置可选的对话模型，通过 one-api 来实现多模型接入。
点击AI模型后，可以配置模型的相关参数。
🍅
具体配置参数介绍可以参考: AI参数配置说明</description></item><item><title>内容提取</title><link>https://doc.tryfastgpt.ai/docs/workflow/modules/content_extract/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/workflow/modules/content_extract/</guid><description>特点 link 可重复添加 需要手动配置 触发执行 function_call 模块 核心模块 功能 link从文本中提取结构化数据，通常是配合 HTTP 模块实现扩展。也可以做一些直接提取操作，例如：翻译。
参数说明 link提取要求描述 link顾名思义，给模型设置一个目标，需要提取哪些内容。
示例 1
你是实验室预约助手，从对话中提取出姓名，预约时间，实验室号。当前时间 {{cTime}}
示例 2
你是谷歌搜索助手，从对话中提取出搜索关键词
示例 3
将我的问题直接翻译成英文，不要回答问题
历史记录 link通常需要一些历史记录，才能更完整的提取用户问题。例如上图中需要提供姓名、时间和实验室名，用户可能一开始只给了时间和实验室名，没有提供自己的姓名。再经过一轮缺失提示后，用户输入了姓名，此时需要结合上一次的记录才能完整的提取出 3 个内容。
目标字段 link目标字段与提取的结果相对应，从上图可以看到，每增加一个字段，输出会增加一个对应的出口。
key: 字段的唯一标识，不可重复！ 字段描述：描述该字段是关于什么的，例如：姓名、时间、搜索词等等。 必须：是否强制模型提取该字段，可能提取出来是空字符串。 输出介绍 link 完整提取结果: 一个 JSON 字符串，包含所有字段的提取结果。 目标字段提取结果：类型均为字符串。</description></item><item><title>自定义反馈</title><link>https://doc.tryfastgpt.ai/docs/workflow/modules/custom_feedback/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/workflow/modules/custom_feedback/</guid><description>该模块为临时模块，后续会针对该模块进行更全面的设计。
特点 link 可重复添加 无外部输入 自动执行 介绍 link自定义反馈模块，可以为你的对话增加一个反馈标记，从而方便在后台更好的分析对话的数据。
在调试模式下，不会记录反馈内容，而是直接提示: 自动反馈测试: 反馈内容。
在对话模式（对话、分享窗口、带 chatId 的 API 调用）时，会将反馈内容记录到对话日志中。（会延迟60s记录）
作用 link自定义反馈模块的功能类似于程序开发的埋点，便于你观测的对话中的数据。</description></item><item><title>HTTP 模块</title><link>https://doc.tryfastgpt.ai/docs/workflow/modules/http/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/workflow/modules/http/</guid><description>特点 link 可重复添加 手动配置 触发执行 核中核模块 介绍 linkHTTP 模块会向对应的地址发送一个 HTTP 请求，实际操作与 Postman 和 ApiFox 这类直流工具使用差不多。
Params 为路径请求参数，GET请求中用的居多。 Body 为请求体，POST/PUT请求中用的居多。 Headers 为请求头，用于传递一些特殊的信息。 自定义变量中可以接收前方节点的输出作为变量 3 种数据中均可以通过 {{}} 来引用变量。 url 也可以通过 {{}} 来引用变量。 变量来自于全局变量、系统变量、前方节点输出 参数结构 link系统变量说明 link你可以将鼠标放置在请求参数旁边的问号中，里面会提示你可用的变量。
appId: 应用的ID chatId: 当前对话的ID，测试模式下不存在。 responseChatItemId: 当前对话中，响应的消息ID，测试模式下不存在。 variables: 当前对话的全局变量。 cTime: 当前时间。 histories: 历史记录（默认最多取10条，无法修改长度） Params, Headers link不多描述，使用方法和Postman, ApiFox 基本一致。
可通过 {{key}} 来引入变量。例如：
key value appId {{appId}} Authorization Bearer {{token}} Body link只有特定请求类型下会生效。
可以写一个自定义的 Json，并通过 {{key}} 来引入变量。例如：
假设有一组变量 Http 模块中的Body声明 最终得到的解析 { &amp;#34;string&amp;#34;: &amp;#34;字符串&amp;#34;, &amp;#34;number&amp;#34;: 123, &amp;#34;boolean&amp;#34;: true, &amp;#34;array&amp;#34;: [1, 2, 3], &amp;#34;obj&amp;#34;: { &amp;#34;name&amp;#34;: &amp;#34;FastGPT&amp;#34;, &amp;#34;url&amp;#34;: &amp;#34;https://fastgpt.</description></item><item><title>Laf 函数调用</title><link>https://doc.tryfastgpt.ai/docs/workflow/modules/laf/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/workflow/modules/laf/</guid><description>介绍 linkLaf 函数调用模块可以调用 Laf 账号下的云函数，其工作原理与 HTTP 模块相同，有以下特殊特征：
只能使用 POST 请求 请求自带系统参数 systemParams，无需通过变量传递。 绑定 Laf 账号 link要调用 Laf 云函数，首先需要绑定 Laf 账号和应用，并且在应用中创建云函数。
Laf 提供了 PAT(访问凭证) 来实现 Laf 平台外的快捷登录，可以访问 Laf 文档查看详细如何获取 PAT。
在获取到 PAT 后，我们可以进入 FastGPT 的账号页或是在高级编排中的 Laf模块 对 Laf 账号进行绑定。Laf 账号是团队共享的，仅团队管理员可配置。
填入 PAT 验证后，选择需要绑定的应用（应用需要是 Running 状态），即可调用该应用下的云函数。
编写云函数 linkLaf 云函数拥有根据 interface 自动生成 OpenAPI 的能力，可以参照下面的代码编写云函数，以便自动生成 OpenAPI 文档。
Laf模块可以根据 OpenAPI 文档，自动识别出入参，无需手动添加数据类型。如果不会写 TS，可忽略，手动在 FastGPT 中添加参数即可。
import cloud from &amp;#39;@lafjs/cloud&amp;#39; interface IRequestBody { // 自定义入参，FastGPT 传入的均为POST请求。 data1: string // 必填参数 data2?</description></item><item><title>对话入口</title><link>https://doc.tryfastgpt.ai/docs/workflow/modules/input/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/workflow/modules/input/</guid><description>特点 link 流程入口 无输入 自动执行</description></item><item><title>工具调用</title><link>https://doc.tryfastgpt.ai/docs/workflow/modules/tool/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/workflow/modules/tool/</guid><description> 什么是工具 link工具可以是一个系统模块，例如：AI对话、知识库搜索、HTTP模块等。也可以是一个插件。
工具调用可以让 LLM 更动态的决策流程，而不都是固定的流程。（当然，缺点就是费tokens）
工具的组成 link 工具介绍。通常是模块的介绍或插件的介绍，这个介绍会告诉LLM，这个工具的作用是什么。 工具参数。对于系统模块来说，工具参数已经是固定的，无需额外配置。对于插件来说，工具参数是一个可配置项。 工具是如何运行的 link要了解工具如何运行的，首先需要知道它的运行条件。
需要工具的介绍（或者叫描述）。这个介绍会告诉LLM，这个工具的作用是什么，LLM会根据上下文语义，决定是否需要调用这个工具。 工具的参数。有些工具调用时，可能需要一些特殊的参数。参数中有2个关键的值：参数介绍和是否必须。 结合工具的介绍、参数介绍和参数是否必须，LLM会决定是否调用这个工具。有以下几种情况：
无参数的工具：直接根据工具介绍，决定是否需要执行。例如：获取当前时间。 有参数的工具： 无必须的参数：尽管上下文中，没有适合的参数，也可以调用该工具。但有时候，LLM会自己伪造一个参数。 有必须的参数：如果没有适合的参数，LLM可能不会调用该工具。可以通过提示词，引导用户提供参数。 工具调用逻辑 link在支持函数调用的模型中，可以一次性调用多个工具，调用逻辑如下：
怎么用 link 有工具调用模块 无工具调用模块 高级编排中，托动工具调用的连接点，可用的工具头部会出现一个菱形，可以将它与工具调用模块底部的菱形相连接。
被连接的工具，会自动分离工具输入与普通的输入，并且可以编辑介绍，可以通过调整介绍，使得该工具调用时机更加精确。
关于工具调用，如何调试仍然是一个玄学，所以建议，不要一次性增加太多工具，选择少量工具调优后再进一步尝试。
相关示例 link 谷歌搜索 发送飞书webhook</description></item><item><title>知识库搜索</title><link>https://doc.tryfastgpt.ai/docs/workflow/modules/dataset_search/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/workflow/modules/dataset_search/</guid><description>知识库搜索具体参数说明，以及内部逻辑请移步：FastGPT知识库搜索方案
特点 link 可重复添加（复杂编排时防止线太乱，可以更美观） 有外部输入 有静态配置 触发执行 核心模块 参数说明 link输入 - 关联的知识库 link可以选择一个或多个相同向量模型的知识库，用于向量搜索。
输入 - 搜索参数 link点击查看参数介绍
输出 - 引用内容 link以数组格式输出引用，长度可以为 0。意味着，即使没有搜索到内容，这个输出链路也会走通。</description></item><item><title>问题分类</title><link>https://doc.tryfastgpt.ai/docs/workflow/modules/question_classify/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/workflow/modules/question_classify/</guid><description>特点 link 可重复添加 有外部输入 需要手动配置 触发执行 function_call 模块 功能 link可以将用户的问题进行分类，分类后执行不同操作。在一些较模糊的场景中，分类效果不是很明显。
参数说明 link系统提示词 link被放置在对话最前面，可用于补充说明分类内容的定义。例如问题会被分为：
打招呼 Laf 常见问题 其他问题 由于 Laf 不是一个明确的东西，需要给它一个定义，此时提示词里可以填入 Laf 的定义：
Laf 是云开发平台，可以快速的开发应用 Laf 是一个开源的 BaaS 开发平台（Backend as a Service) Laf 是一个开箱即用的 serverless 开发平台 Laf 是一个集「函数计算」、「数据库」、「对象存储」等于一身的一站式开发平台 Laf 可以是开源版的腾讯云开发、开源版的 Google Firebase、开源版的 UniCloud 聊天记录 link适当增加一些聊天记录，可以联系上下文进行分类。
用户问题 link用户输入的内容。
分类内容 link依然以这 3 个分类为例，可以看到最终组成的 Function。其中返回值由系统随机生成，不需要关心。
打招呼 Laf 常见问题 其他问题 const agentFunction = { name: agentFunName, description: &amp;#39;判断用户问题的类型属于哪方面，返回对应的枚举字段&amp;#39;, parameters: { type: &amp;#39;object&amp;#39;, properties: { type: { type: &amp;#39;string&amp;#39;, description: `打招呼，返回: abc；Laf 常见问题，返回：vvv；其他问题，返回：aaa` enum: [&amp;#34;abc&amp;#34;,&amp;#34;vvv&amp;#34;,&amp;#34;aaa&amp;#34;] } }, required: [&amp;#39;type&amp;#39;] } }; 上面的 Function 必然会返回 type = abc，vvv，aaa 其中一个值，从而实现分类判断。</description></item><item><title>指定回复</title><link>https://doc.tryfastgpt.ai/docs/workflow/modules/reply/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/workflow/modules/reply/</guid><description>特点 link 可重复添加（防止复杂编排时线太乱，重复添加可以更美观） 可手动输入 可外部输入 会输出结果给客户端 指定回复模块通常用户特殊状态回复，回复内容有两种：
一种是手动输入固定内容。 一种是通过变量引用。 图 1</description></item><item><title>判断器</title><link>https://doc.tryfastgpt.ai/docs/workflow/modules/tfswitch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/workflow/modules/tfswitch/</guid><description>特点 link 可重复添加 有外部输入 触发执行 功能 link对任意变量进行IF判断，若满足条件则执行IF分支，不满足条件执行ELSE分支。
上述例子中若「知识库引用」变量的长度等于0则执行IF分支，否则执行ELSE分支。
支持增加更多的判断条件和分支，同编程语言中的IF语句逻辑相同。
作用 link适用场景有：让大模型做判断后输出固定内容，根据大模型回复内容判断是否触发后续模块。</description></item><item><title>文本加工</title><link>https://doc.tryfastgpt.ai/docs/workflow/modules/text_editor/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/workflow/modules/text_editor/</guid><description>特点 link 可重复添加 有外部输入 触发执行 手动配置 功能 link对输入文本进行固定加工处理，入参仅支持字符串和数字格式，入参以变量形式使用在文本编辑区域。
根据上方示例图的处理方式，对任何输入都会在前面拼接“用户的问题是:”。
作用 link给任意模块输入自定格式文本，或处理 AI 模块系统提示词。
示例 link 接入谷歌搜索</description></item><item><title>问题优化（已合并到知识库搜索）</title><link>https://doc.tryfastgpt.ai/docs/workflow/modules/coreferenceresolution/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/workflow/modules/coreferenceresolution/</guid><description>特点 link 可重复添加 有外部输入 触发执行 背景 link在 RAG 中，我们需要根据输入的问题去数据库里执行 embedding 搜索，查找相关的内容，从而查找到相似的内容（简称知识库搜索）。
在搜索的过程中，尤其是连续对话的搜索，我们通常会发现后续的问题难以搜索到合适的内容，其中一个原因是知识库搜索只会使用“当前”的问题去执行。看下面的例子：
用户在提问“第二点是什么”的时候，只会去知识库里查找“第二点是什么”，压根查不到内容。实际上需要查询的是“QA结构是什么”。因此我们需要引入一个【问题优化】模块，来对用户当前的问题进行补全，从而使得知识库搜索能够搜索到合适的内容。使用补全后效果如下：
功能 link调用 AI 去对用户当前的问题进行补全。目前主要是补全“指代”词，使得检索词更加的完善可靠，从而增强上下文连续对话的知识库搜索能力。
遇到最大的难题在于：模型对于【补全】的概念可能不清晰，且对于长上下文往往无法准确的知道应该如何补全。
示例 link 接入谷歌搜索</description></item><item><title>长字幕翻译</title><link>https://doc.tryfastgpt.ai/docs/workflow/examples/translate-subtitle-using-gpt/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/workflow/examples/translate-subtitle-using-gpt/</guid><description>直接使用 LLM 来翻译长字幕会遇到很多难点，这些难点也正是直接使用 AI 无法有效处理的问题：
Tokens 限制：这是最明显的障碍。大语言模型 (LLM) 通常有输出 tokens 的限制，这意味着对于长文本，如果不使用特殊的工作流，可能需要手动将文本分段，逐段输入 AI 进行翻译，然后再手动拼接结果。这个过程不仅繁琐，还容易出错。
字幕格式的保持：对于字幕来说，时间轴信息至关重要。然而，AI 模型有时会产生 “幻觉”，即无中生有地修改或生成不存在的信息。在字幕翻译中，这可能导致 AI 错误地修改时间轴，使字幕与音频不同步。
翻译质量：简单的机器翻译往往无法满足观众的需求。即使是大语言模型，单轮翻译的质量也常常不尽如人意。对于字幕来说，翻译质量直接影响观看体验，糟糕的翻译会严重影响观众的沉浸感。
本案例将展示如何利用 FastGPT 工作流代码结合 LLM 来有效解决这些问题。我们的方法不仅能克服技术限制，还能显著提升翻译质量。
提取字幕信息 link工作流的一大优势在于可以结合额外的操作，使 AI 能更精准地处理信息。在字幕翻译中，我们可以先分离 SRT 字幕文件的各个组成部分，然后只让 LLM 翻译文本部分。这种方法既节约了 token 使用，又确保了时间轴信息不被误改。
具体实现如下：
使用代码执行模块，对输入的原始字幕文本进行解析。 将字幕信息分类为三部分：时间信息、序号信息和文本信息。 只保留文本信息用于后续的 AI 翻译。 这种预处理步骤大大提高了整个翻译过程的效率和准确性。
切分文本 link为了进一步优化翻译过程，我们需要将提取出的文本信息重新组织。这一步的目的是将文本分割成适合 LLM 处理的大小，同时保持上下文的连贯性。
在本例中，我们采用以下策略：
将文本按照每 40 句为一组进行切分。这个数字是经过多次测试后得出的平衡点，既能保证翻译质量，又不会超出 LLM 的处理能力。 使用 标签分割每句文本。这种标记方法便于后续的重新组装，同时也为 AI 模型提供了清晰的句子边界。 这种切分方法既考虑了 AI 模型的能力限制，又保证了翻译的连贯性。通过保持适当的上下文，我们可以得到更加准确和自然的翻译结果。
格式化原文本 link在这一步，我们构建了最终输入给 LLM 的原文本。这个步骤的关键在于如何在控制 tokens 数量的同时，为 AI 提供足够的上下文信息。我们采用了以下策略：
传入所有文本作为背景上下文。这确保 AI 能理解整段对话的语境。 使用&amp;lt;TRANSLATE_THIS&amp;gt;标签明确指出当前需要翻译的片段。这种方法既能控制 AI 的输出范围，又不会丢失整体语境。 这种格式化方法使得 AI 能在理解全局的基础上，专注于翻译特定部分，从而提高翻译的准确性和连贯性。</description></item><item><title>固定开头和结尾内容</title><link>https://doc.tryfastgpt.ai/docs/workflow/examples/fixingevidence/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/workflow/examples/fixingevidence/</guid><description>如上图，可以通过指定回复编排一个固定的开头和结尾内容。
模块编排 link复制下面配置，点击「高级编排」右上角的导入按键，导入该配置。
编排配置 { &amp;#34;nodes&amp;#34;: [ { &amp;#34;nodeId&amp;#34;: &amp;#34;7z5g5h&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;流程开始&amp;#34;, &amp;#34;intro&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;avatar&amp;#34;: &amp;#34;/imgs/workflow/userChatInput.svg&amp;#34;, &amp;#34;flowNodeType&amp;#34;: &amp;#34;workflowStart&amp;#34;, &amp;#34;position&amp;#34;: { &amp;#34;x&amp;#34;: -269.50851681351924, &amp;#34;y&amp;#34;: 1657.6123698022448 }, &amp;#34;inputs&amp;#34;: [ { &amp;#34;key&amp;#34;: &amp;#34;userChatInput&amp;#34;, &amp;#34;renderTypeList&amp;#34;: [ &amp;#34;reference&amp;#34;, &amp;#34;textarea&amp;#34; ], &amp;#34;valueType&amp;#34;: &amp;#34;string&amp;#34;, &amp;#34;label&amp;#34;: &amp;#34;问题输入&amp;#34;, &amp;#34;required&amp;#34;: true, &amp;#34;toolDescription&amp;#34;: &amp;#34;用户问题&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;systemInput&amp;#34;, &amp;#34;showTargetInApp&amp;#34;: false, &amp;#34;showTargetInPlugin&amp;#34;: false, &amp;#34;connected&amp;#34;: false, &amp;#34;selectedTypeIndex&amp;#34;: 0, &amp;#34;value&amp;#34;: [ &amp;#34;7z5g5h&amp;#34;, &amp;#34;userChatInput&amp;#34; ] } ], &amp;#34;outputs&amp;#34;: [ { &amp;#34;id&amp;#34;: &amp;#34;userChatInput&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;static&amp;#34;, &amp;#34;key&amp;#34;: &amp;#34;userChatInput&amp;#34;, &amp;#34;valueType&amp;#34;: &amp;#34;string&amp;#34;, &amp;#34;label&amp;#34;: &amp;#34;core.</description></item><item><title>接入谷歌搜索</title><link>https://doc.tryfastgpt.ai/docs/workflow/examples/google_search/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/workflow/examples/google_search/</guid><description>工具调用模式 工具调用模式 非工具调用模式 非工具调用模式 如上图，利用「HTTP请求」模块，你可以外接一个搜索引擎作为 AI 回复的参考资料。这里以调用 Google Search API 为例。注意：本文主要是为了介绍 「HTTP请求」模块，具体的搜索效果需要依赖提示词和搜索引擎，尤其是【搜索引擎】，简单的搜索引擎无法获取更详细的内容，这部分可能需要更多的调试。
注册 Google Search API link参考这篇文章，每天可以免费使用 100 次。
写一个 Google Search 接口 link这里用 Laf 快速实现一个接口，即写即发布，无需部署。务必打开 POST 请求方式。
Laf 谷歌搜索Demo import cloud from &amp;#39;@lafjs/cloud&amp;#39; const googleSearchKey = &amp;#34;xxx&amp;#34; const googleCxId = &amp;#34;3740cxxx&amp;#34; const baseurl = &amp;#34;https://www.googleapis.com/customsearch/v1&amp;#34; type RequestType = { searchKey: string } export default async function (ctx: FunctionContext) { const { searchKey } = ctx.body as RequestType console.log(ctx.body) if (!</description></item><item><title>实验室预约</title><link>https://doc.tryfastgpt.ai/docs/workflow/examples/lab_appointment/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/workflow/examples/lab_appointment/</guid><description>本示例演示了利用工具调用，自动选择调用知识库搜索实验室相关内容，或调用 HTTP 模块实现数据库的 CRUD 操作。
以一个实验室预约为例，用户可以通过对话系统预约、取消、修改预约和查询预约记录。
1. 全局变量使用 link通过设计一个全局变量，让用户输入姓名，模拟用户身份信息。实际使用过程中，通常是直接通过嵌入 Token 来标记用户身份。
2. 工具调用 link 背景知识中，引导模型调用工具去执行不通的操作。
🤗
Tips: 这里需要增加适当的上下文，方便模型结合历史纪录进行判断和决策~
3. HTTP 模块 link HTTP模块中，需要设置 3 个工具参数：
预约行为：可取 get, put, post, delete 四个值，分别对应查询、修改、新增、删除操作。当然，你也可以写4个HTTP模块，来分别处理。 labname: 实验室名。非必填，因为查询和删除时候，不需要。 time: 预约时间。 总结 link 工具调用模块是非常强大的功能，可以在一定程度上替代问题分类和内容提取。 通过工具模块，动态的调用不同的工具，可以将复杂业务解耦。 附件 link编排配置 link可直接复制，导入到 FastGPT 中。
编排配置 { &amp;#34;nodes&amp;#34;: [ { &amp;#34;nodeId&amp;#34;: &amp;#34;userChatInput&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;流程开始&amp;#34;, &amp;#34;intro&amp;#34;: &amp;#34;当用户发送一个内容后，流程将会从这个模块开始执行。&amp;#34;, &amp;#34;avatar&amp;#34;: &amp;#34;/imgs/workflow/userChatInput.svg&amp;#34;, &amp;#34;flowNodeType&amp;#34;: &amp;#34;workflowStart&amp;#34;, &amp;#34;position&amp;#34;: { &amp;#34;x&amp;#34;: 309.7143912167367, &amp;#34;y&amp;#34;: 1501.2761754220846 }, &amp;#34;inputs&amp;#34;: [ { &amp;#34;key&amp;#34;: &amp;#34;userChatInput&amp;#34;, &amp;#34;renderTypeList&amp;#34;: [ &amp;#34;reference&amp;#34;, &amp;#34;textarea&amp;#34; ], &amp;#34;valueType&amp;#34;: &amp;#34;string&amp;#34;, &amp;#34;label&amp;#34;: &amp;#34;问题输入&amp;#34;, &amp;#34;required&amp;#34;: true, &amp;#34;toolDescription&amp;#34;: &amp;#34;用户问题&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;systemInput&amp;#34;, &amp;#34;showTargetInApp&amp;#34;: false, &amp;#34;showTargetInPlugin&amp;#34;: false, &amp;#34;connected&amp;#34;: false, &amp;#34;selectedTypeIndex&amp;#34;: 0, &amp;#34;value&amp;#34;: [ &amp;#34;userChatInput&amp;#34;, &amp;#34;userChatInput&amp;#34; ] } ], &amp;#34;outputs&amp;#34;: [ { &amp;#34;id&amp;#34;: &amp;#34;userChatInput&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;static&amp;#34;, &amp;#34;key&amp;#34;: &amp;#34;userChatInput&amp;#34;, &amp;#34;valueType&amp;#34;: &amp;#34;string&amp;#34;, &amp;#34;label&amp;#34;: &amp;#34;core.</description></item><item><title>Dalle3 绘图</title><link>https://doc.tryfastgpt.ai/docs/workflow/examples/dalle3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/workflow/examples/dalle3/</guid><description>OpenAI Dalle3 接口 link先来看下官方接口的参数和响应值：
Body
{ &amp;#34;model&amp;#34;: &amp;#34;dall-e-3&amp;#34;, &amp;#34;prompt&amp;#34;: &amp;#34;A cute baby sea otter&amp;#34;, &amp;#34;n&amp;#34;: 1, &amp;#34;size&amp;#34;: &amp;#34;1024x1024&amp;#34; } Response
{ &amp;#34;created&amp;#34;: 1589478378, &amp;#34;data&amp;#34;: [ { &amp;#34;url&amp;#34;: &amp;#34;https://...&amp;#34; }, { &amp;#34;url&amp;#34;: &amp;#34;https://...&amp;#34; } ] } 编排思路 link 通过 AI 来优化图片绘制的提示词（这步省略了，自己找提示词即可） 通过 【HTTP 请求】模块 调用 Dalle3 接口，获取图片的 URL。 通过 【文本加工】模块 来构建 Markdown 的图片格式。 通过 【指定回复】模块 来直接输出图片链接。 1. 构建 HTTP 模块 link请求参数直接复制 Dalle3 接口的即可，并求改 prompt 为变量。需要增加一个 Headers.Authorization 。
Body:
{ &amp;#34;model&amp;#34;: &amp;#34;dall-e-3&amp;#34;, &amp;#34;prompt&amp;#34;: &amp;#34;{{prompt}}&amp;#34;, &amp;#34;n&amp;#34;: 1, &amp;#34;size&amp;#34;: &amp;#34;1024x1024&amp;#34; } Headers:</description></item><item><title>发送飞书webhook通知</title><link>https://doc.tryfastgpt.ai/docs/workflow/examples/feishu_webhook/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/workflow/examples/feishu_webhook/</guid><description>该文章展示如何发送一个简单的飞书webhook通知，以此类推，发送其他类型的通知也可以这么操作。
1. 准备飞书机器人 link 2. 导入编排代码 link复制下面配置，点击「高级编排」右上角的导入按键，导入该配置，导入后将飞书提供的接口地址复制到「HTTP 模块」。
编排配置 { &amp;#34;nodes&amp;#34;: [ { &amp;#34;nodeId&amp;#34;: &amp;#34;userGuide&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;系统配置&amp;#34;, &amp;#34;intro&amp;#34;: &amp;#34;可以配置应用的系统参数&amp;#34;, &amp;#34;avatar&amp;#34;: &amp;#34;/imgs/workflow/userGuide.png&amp;#34;, &amp;#34;flowNodeType&amp;#34;: &amp;#34;userGuide&amp;#34;, &amp;#34;position&amp;#34;: { &amp;#34;x&amp;#34;: 303.41163758039283, &amp;#34;y&amp;#34;: -552.297639861266 }, &amp;#34;version&amp;#34;: &amp;#34;481&amp;#34;, &amp;#34;inputs&amp;#34;: [], &amp;#34;outputs&amp;#34;: [] }, { &amp;#34;nodeId&amp;#34;: &amp;#34;workflowStartNodeId&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;流程开始&amp;#34;, &amp;#34;intro&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;avatar&amp;#34;: &amp;#34;/imgs/workflow/userChatInput.svg&amp;#34;, &amp;#34;flowNodeType&amp;#34;: &amp;#34;workflowStart&amp;#34;, &amp;#34;position&amp;#34;: { &amp;#34;x&amp;#34;: 529.3935295017156, &amp;#34;y&amp;#34;: 197.114018410347 }, &amp;#34;version&amp;#34;: &amp;#34;481&amp;#34;, &amp;#34;inputs&amp;#34;: [ { &amp;#34;key&amp;#34;: &amp;#34;userChatInput&amp;#34;, &amp;#34;renderTypeList&amp;#34;: [ &amp;#34;reference&amp;#34;, &amp;#34;textarea&amp;#34; ], &amp;#34;valueType&amp;#34;: &amp;#34;string&amp;#34;, &amp;#34;label&amp;#34;: &amp;#34;用户问题&amp;#34;, &amp;#34;required&amp;#34;: true, &amp;#34;toolDescription&amp;#34;: &amp;#34;用户问题&amp;#34; } ], &amp;#34;outputs&amp;#34;: [ { &amp;#34;id&amp;#34;: &amp;#34;userChatInput&amp;#34;, &amp;#34;key&amp;#34;: &amp;#34;userChatInput&amp;#34;, &amp;#34;label&amp;#34;: &amp;#34;core.</description></item><item><title>使用 Gapier 快速导入Agent工具</title><link>https://doc.tryfastgpt.ai/docs/use-cases/gapier/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/use-cases/gapier/</guid><description>FastGPT V4.7版本加入了工具调用，可以兼容 GPTs 的 Actions。这意味着，你可以直接导入兼容 GPTs 的 Agent 工具。
Gapier 是一个在线 GPTs Actions工具，提供了50多种现成工具，并且每天有免费额度进行测试，方便用户试用，官方地址为：https://gapier.com/。
现在，我们开始把 Gapier 的工具导入到 FastGPT 中。
1. 创建插件 link Step1 Step2 Step3 登录Gapier 复制相关参数 Step4 Step5 Step6 自定义请求头: Authorization
请求值: Bearer 复制的key 创建完后，如果需要变更，无需重新创建，只需要修改对应参数即可，会自动做差值比较更新。
2. 应用绑定工具 link简易模式 link Step1 Step2 Step3 Step4 高级编排 link Step1 Step2 Step3 Step4 3. 工具调用说明 link不同模型的区别 link不同模型调用工具采用不同的方法，有些模型支持 toolChoice 和 functionCall 效果会更好。不支持这两种方式的模型通过提示词调用，但是效果不是很好，并且为了保证顺利调用，FastGPT内置的提示词，仅支持每次调用一个工具。
具体哪些模型支持 functionCall 可以官网查看（当然，也需要OneAPI支持），同时需要调整模型配置文件中的对应字段（详细看配置字段说明）。
线上版用户，可以在模型选择时，看到是否支持函数调用的标识。</description></item><item><title>对接 chatgpt-on-wechat</title><link>https://doc.tryfastgpt.ai/docs/use-cases/onwechat/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/use-cases/onwechat/</guid><description>1 分钟对接 chatgpt-on-wechat linkchatgpt-on-wechat GitHub 地址
由于 FastGPT 的 API 接口和 OpenAI 的规范一致，可以无需变更原来的应用即可使用 FastGPT 上编排好的应用。API 使用可参考 这篇文章。编排示例，可参考 高级编排介绍
1. 获取 OpenAPI 密钥 link依次选择应用 -&amp;gt; 「API访问」，然后点击「API 密钥」来创建密钥。
warning 密钥需要自己保管好，一旦关闭就无法再复制密钥，只能创建新密钥再复制。
3. 创建 docker-compose.yml 文件 link只需要修改 OPEN_AI_API_KEY 和 OPEN_AI_API_BASE 两个环境变量即可。其中 OPEN_AI_API_KEY 为第一步获取的密钥，OPEN_AI_API_BASE 为 FastGPT 的 OpenAPI 地址，例如：https://api.fastgpt.in/api/v1。
随便找一个目录，创建一个 docker-compose.yml 文件，将下面的代码复制进去。
version: &amp;#39;2.0&amp;#39; services: chatgpt-on-wechat: image: zhayujie/chatgpt-on-wechat container_name: chatgpt-on-wechat security_opt: - seccomp:unconfined environment: OPEN_AI_API_KEY: &amp;#39;fastgpt-z51pkjqm9nrk03a1rx2funoy&amp;#39; OPEN_AI_API_BASE: &amp;#39;https://api.fastgpt.in/api/v1&amp;#39; MODEL: &amp;#39;gpt-3.5-turbo&amp;#39; CHANNEL_TYPE: &amp;#39;wx&amp;#39; PROXY: &amp;#39;&amp;#39; HOT_RELOAD: &amp;#39;False&amp;#39; SINGLE_CHAT_PREFIX: &amp;#39;[&amp;#34;bot&amp;#34;, &amp;#34;@bot&amp;#34;]&amp;#39; SINGLE_CHAT_REPLY_PREFIX: &amp;#39;&amp;#34;[bot] &amp;#34;&amp;#39; GROUP_CHAT_PREFIX: &amp;#39;[&amp;#34;@bot&amp;#34;]&amp;#39; GROUP_NAME_WHITE_LIST: &amp;#39;[&amp;#34;ChatGPT测试群&amp;#34;, &amp;#34;ChatGPT测试群2&amp;#34;]&amp;#39; IMAGE_CREATE_PREFIX: &amp;#39;[&amp;#34;画&amp;#34;, &amp;#34;看&amp;#34;, &amp;#34;找&amp;#34;]&amp;#39; CONVERSATION_MAX_TOKENS: 1000 SPEECH_RECOGNITION: &amp;#39;False&amp;#39; CHARACTER_DESC: &amp;#39;你是ChatGPT, 一个由OpenAI训练的大型语言模型, 你旨在回答并解决人们的任何问题，并且可以使用多种语言与人交流。&amp;#39; SUBSCRIBE_MSG: &amp;#39;感谢您的关注！\n这里是ChatGPT，可以自由对话。\n支持语音对话。\n支持图片输入。\n支持图片输出，画字开头的消息将按要求创作图片。\n支持tool、角色扮演和文字冒险等丰富的插件。\n输入{trigger_prefix}#help 查看详细指令。&amp;#39; EXPIRES_IN_SECONDS: 3600 USE_GLOBAL_PLUGIN_CONFIG: &amp;#39;True&amp;#39; USE_LINKAI: &amp;#39;False&amp;#39; LINKAI_API_KEY: &amp;#39;&amp;#39; LINKAI_APP_CODE: &amp;#39;&amp;#39; 4.</description></item><item><title>接入微信和企业微信</title><link>https://doc.tryfastgpt.ai/docs/use-cases/wechat/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/use-cases/wechat/</guid><description>FastGPT 三分钟接入微信/企业微信 link私人微信和企业微信接入的方式基本一样，不同的地方会刻意指出。
查看视频教程
创建APIKey link首先找到我们需要接入的应用，然后点击「外部使用」-&amp;gt;「API访问」创建一个APIKey并保存。
配置微秘书 link打开微秘书 注册登录后找到菜单栏「基础配置」-&amp;gt;「智能配置」，按照下图配置。
继续往下看到 apikey 和服务器根地址，这里apikey填写我们在 FastGPT 应用外部访问中创建的 APIkey，服务器根地址填写官方地址或者私有化部署的地址，这里用官方地址示例，注意要添加/v1后缀,填写完毕后保存。
sealos部署服务 link访问sealos 登录进来之后打开「应用管理」-&amp;gt; 「新建应用」。
应用名：称随便填写 镜像名：私人微信填写 aibotk/wechat-assistant 企业微信填写 aibotk/worker-assistant cpu和内存建议 1c1g 往下翻页找到「高级配置」-&amp;gt; 「编辑环境变量」
这里需要填写三个环境变量：
AIBOTK_KEY=微秘书 APIKEY AIBOTK_SECRET=微秘书 APISECRET WORK_PRO_TOKEN=你申请的企微 token （企业微信需要填写，私人微信不需要） 这里最后的企业微信 Token 在微秘书的-&amp;gt;会员开通栏目中自行购买。
这里环境变量我们介绍下如何填写：
AIBOTK_KEY 和 AIBOTK_SECRET 我们需要回到微秘书找到「个人中心」,这里的 APIKEY 对应 AIBOTK_KEY ，APISECRET 对应 AIBOTK_SECRET。
WORK_PRO_TOKEN 微秘书的会员中心中自行购买即可。
填写完毕后点右上角「部署」，等待应用状态变为运行中。
返回微秘书 找到「首页」，扫码登录需要接入的微信号。
测试 link只需要发送信息，或者拉入群聊@登录的微信就会回复信息啦。</description></item><item><title>快速开始本地开发</title><link>https://doc.tryfastgpt.ai/docs/development/intro/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/intro/</guid><description>本文档介绍了如何设置开发环境以构建和测试 FastGPT，。
前置依赖项 link您需要在计算机上安装和配置以下依赖项才能构建 FastGPT：
Git Docker（构建镜像） Node.js v18.17 / v20.x（版本尽量一样，可以使用nvm管理node版本） pnpm 版本 8.6.0 (目前官方的开发环境) make命令: 根据不同平台，百度安装 (官方是GNU Make 4.3) 开始本地开发 link check_circle 用户默认的时区为 Asia/Shanghai,非 linux 环境时候，获取系统时间会异常，本地开发时候，可以将用户的时区调整成 UTC（+0）。 建议先服务器装好数据库，再进行本地开发。 1. Fork 存储库 link您需要 Fork 存储库。
2. 克隆存储库 link克隆您在 GitHub 上 Fork 的存储库：
git clone git@github.com:&amp;lt;github_username&amp;gt;/FastGPT.git 目录简要说明
projects 目录下为 FastGPT 应用代码。其中 app 为 FastGPT 核心应用。（后续可能会引入其他应用） NextJS 框架前后端放在一起，API 服务位于 src/pages/api 目录内。 packages 目录为共用代码，通过 workspace 被注入到 projects 中，已配置 monorepo 自动注入，无需额外打包。 3. 安装数据库 link第一次开发，需要先部署数据库，建议本地开发可以随便找一台 2C2G 的轻量小数据库实践，或者新建文件夹并配置相关文件用以运行docker。数据库部署教程：Docker 快速部署。部署完了，可以本地访问其数据库。</description></item><item><title>Sealos 一键部署</title><link>https://doc.tryfastgpt.ai/docs/development/sealos/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/sealos/</guid><description>部署架构图 link 多模型支持 linkFastGPT 使用了 one-api 项目来管理模型池，其可以兼容 OpenAI 、Azure 、国内主流模型和本地模型等。
可参考：Sealos 快速部署 OneAPI
一键部署 link使用 Sealos 服务，无需采购服务器、无需域名，支持高并发 &amp;amp; 动态伸缩，并且数据库应用采用 kubeblocks 的数据库，在 IO 性能方面，远超于简单的 Docker 容器部署。可以根据需求，再下面两个区域选择部署。
新加坡区 link新加披区的服务器在国外，可以直接访问 OpenAI，但国内用户需要梯子才可以正常访问新加坡区。国际区价格稍贵，点击下面按键即可部署👇
北京区 link北京区服务提供商为火山云，国内用户可以稳定访问，但无法访问 OpenAI 等境外服务，价格约为新加坡区的 1/4。点击下面按键即可部署👇
开始部署 link由于需要部署数据库，部署完后需要等待 2~4 分钟才能正常访问。默认用了最低配置，首次访问时会有些慢。
根据提示，输入root_password，和 openai/oneapi 的地址和密钥。
点击部署后，会跳转到应用管理页面。可以点击fastgpt主应用右侧的详情按键（名字为 fastgpt-xxxx）， 如下图所示。
点击详情后，会跳转到 fastgpt 的部署管理页面，点击外网访问地址中的链接，即可打开 fastgpt 服务。
如需绑定自定义域名、修改部署参数，可以点击右上角变更，根据 sealos 的指引完成。
登录 link用户名：root
密码是刚刚一键部署时设置的root_password
修改配置文件和环境变量 link在 Sealos 中，你可以打开应用管理（App Launchpad）看到部署的 FastGPT，可以打开数据库（Database）看到对应的数据库。
在应用管理中，选中 FastGPT，点击变更，可以看到对应的环境变量和配置文件。
🤖
在 Sealos 上，FastGPT 一共运行了 1 个服务和 2 个数据库，如暂停和删除请注意数据库一同操作。（你可以白天启动，晚上暂停它们，省钱大法）</description></item><item><title>Docker Compose 快速部署</title><link>https://doc.tryfastgpt.ai/docs/development/docker/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/docker/</guid><description>部署架构图 link 🤖
MongoDB：用于存储除了向量外的各类数据
PostgreSQL/Milvus：存储向量数据
OneAPI: 聚合各类 AI API，支持多模型调用 （任何模型问题，先自行通过 OneAPI 测试校验）
推荐配置 linkPgVector版本 link体验测试首选
环境 最低配置（单节点） 推荐配置 测试 2c2g 2c4g 100w 组向量 4c8g 50GB 4c16g 50GB 500w 组向量 8c32g 200GB 16c64g 200GB Milvus版本 link对于千万级以上向量性能更优秀。
点击查看 Milvus 官方推荐配置
环境 最低配置（单节点） 推荐配置 测试 2c8g 4c16g 100w 组向量 未测试 500w 组向量 zilliz cloud版本 link亿级以上向量首选。
由于向量库使用了 Cloud，无需占用本地资源，无需太关注。
前置工作 link1. 确保网络环境 link如果使用OpenAI等国外模型接口，请确保可以正常访问，否则会报错：Connection error 等。 方案可以参考：代理方案
2. 准备 Docker 环境 link Linux MacOS Windows # 安装 Docker curl -fsSL https://get.</description></item><item><title>配置文件介绍</title><link>https://doc.tryfastgpt.ai/docs/development/configuration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/configuration/</guid><description>由于环境变量不利于配置复杂的内容，新版 FastGPT 采用了 ConfigMap 的形式挂载配置文件，你可以在 projects/app/data/config.json 看到默认的配置文件。可以参考 docker-compose 快速部署 来挂载配置文件。
开发环境下，你需要将示例配置文件 config.json 复制成 config.local.json 文件才会生效。
这个配置文件中包含了系统参数和各个模型配置：
4.6.8+ 版本新配置文件 linkllm模型全部合并
{ &amp;#34;feConfigs&amp;#34;: { &amp;#34;lafEnv&amp;#34;: &amp;#34;https://laf.dev&amp;#34; // laf环境。 https://laf.run （杭州阿里云） ,或者私有化的laf环境。如果使用 Laf openapi 功能，需要最新版的 laf 。 }, &amp;#34;systemEnv&amp;#34;: { &amp;#34;vectorMaxProcess&amp;#34;: 15, &amp;#34;qaMaxProcess&amp;#34;: 15, &amp;#34;pgHNSWEfSearch&amp;#34;: 100 // 向量搜索参数。越大，搜索越精确，但是速度越慢。设置为100，有99%&amp;#43;精度。 }, &amp;#34;llmModels&amp;#34;: [ { &amp;#34;model&amp;#34;: &amp;#34;gpt-3.5-turbo&amp;#34;, // 模型名(对应OneAPI中渠道的模型名) &amp;#34;name&amp;#34;: &amp;#34;gpt-3.5-turbo&amp;#34;, // 别名 &amp;#34;avatar&amp;#34;: &amp;#34;/imgs/model/openai.svg&amp;#34;, // 模型的logo &amp;#34;maxContext&amp;#34;: 16000, // 最大上下文 &amp;#34;maxResponse&amp;#34;: 4000, // 最大回复 &amp;#34;quoteMaxToken&amp;#34;: 13000, // 最大引用内容 &amp;#34;maxTemperature&amp;#34;: 1.</description></item><item><title>使用 One API 接入 Azure、ChatGLM 和本地模型</title><link>https://doc.tryfastgpt.ai/docs/development/one-api/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/one-api/</guid><description>默认情况下，FastGPT 只配置了 GPT 的模型，如果你需要接入其他模型，需要进行一些额外配置。 One API 是一个 OpenAI 接口管理 &amp;amp; 分发系统，可以通过标准的 OpenAI API 格式访问所有的大模型，开箱即用。 FastGPT 可以通过接入 One API 来实现对不同大模型的支持。One API 的部署方法也很简单。 FastGPT 与 One API 关系 link可以把 One API 当做一个网关。
部署 linkDocker 版本 link已加入最新的 docker-compose.yml 文件中。
Sealos - MySQL 版本 linkMySQL 版本支持多实例，高并发。
直接点击以下按钮即可一键部署 👇
部署完后会跳转「应用管理」，数据库在另一个应用「数据库」中。需要等待 1~3 分钟数据库运行后才能访问成功。
Sealos - SqlLite 版本 linkSqlLite 版本不支持多实例，适合个人小流量使用，但是价格非常便宜。
1. 点击打开 Sealos 公有云
2. 打开 AppLaunchpad(应用管理) 工具
3. 点击创建新应用
4. 填写对应参数
镜像：ghcr.io/songquanpeng/one-api:latest
打开外网访问开关后，Sealos 会自动分配一个可访问的地址，不需要自己配置。
填写完参数后，点击右上角部署即可。环境变量：</description></item><item><title>私有部署常见问题</title><link>https://doc.tryfastgpt.ai/docs/development/faq/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/faq/</guid><description>一、错误排查方式 link遇到问题先按下面方式排查。
docker ps -a 查看所有容器运行状态，检查是否全部 running，如有异常，尝试docker logs 容器名查看对应日志。 容器都运行正常的，docker logs 容器名 查看报错日志 带有requestId的，都是 OneAPI 提示错误，大部分都是因为模型接口报错。 无法解决时，可以找找Issue，或新提 Issue，私有部署错误，务必提供详细的日志，否则很难排查。 二、通用问题 link能否纯本地运行 link可以。需要准备好向量模型和LLM模型。
其他模型没法进行问题分类/内容提取 link 看日志。如果提示 JSON invalid，not support tool 之类的，说明该模型不支持工具调用或函数调用，需要设置toolChoice=false和functionCall=false，就会默认走提示词模式。目前内置提示词仅针对了商业模型API进行测试。问题分类基本可用，内容提取不太行。 如果已经配置正常，并且没有错误日志，则说明可能提示词不太适合该模型，可以通过修改customCQPrompt来自定义提示词。 页面崩溃 link 关闭翻译 检查配置文件是否正常加载，如果没有正常加载会导致缺失系统信息，在某些操作下会导致空指针。 95%情况是配置文件不对。会提示 xxx undefined 提示URI malformed，请 Issue 反馈具体操作和页面，这是由于特殊字符串编码解析报错。 某些api不兼容问题（较少） 开启内容补全后，响应速度变慢 link 问题补全需要经过一轮AI生成。 会进行3~5轮的查询，如果数据库性能不足，会有明显影响。 对话接口报错或返回为空(core.chat.Chat API is error or undefined) link 检查 AI 的 key 问题：通过 curl 请求看是否正常。务必用 stream=true 模式。并且 maxToken 等相关参数尽量一致。 如果是国内模型，可能是命中风控了。 查看模型请求日志，检查出入参数是否异常。 # curl 例子。 curl --location --request POST &amp;#39;https://xxx.</description></item><item><title>升级说明</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/intro/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/intro/</guid><description>FastGPT 升级包括两个步骤：
镜像升级 执行升级初始化脚本 镜像名 linkgit版
FastGPT 主镜像：ghcr.io/labring/fastgpt:latest 商业版镜像：ghcr.io/c121914yu/fastgpt-pro:latest Admin 镜像：ghcr.io/c121914yu/fastgpt-admin:latest 阿里云
FastGPT 主镜像: registry.cn-hangzhou.aliyuncs.com/fastgpt/fastgpt 商业版镜像：ghcr:registry.cn-hangzhou.aliyuncs.com/fastgpt/fastgpt-pro Admin 镜像: registry.cn-hangzhou.aliyuncs.com/fastgpt/fastgpt-admin 镜像由镜像名和Tag组成，例如: registry.cn-hangzhou.aliyuncs.com/fastgpt/fastgpt:v4.6.1 代表4.6.3版本镜像，具体可以看 docker hub, github 仓库。
Sealos 修改镜像 link 打开 Sealos Cloud， 找到桌面上的应用管理 选择对应的应用 - 点击右边三个点 - 变更 修改镜像 - 确认变更
如果要修改配置文件，可以拉到下面的配置文件进行修改。
Docker-Compose 修改镜像 link直接修改yml文件中的image: 即可。随后执行:
docker-compose pull docker-compose up -d 执行升级初始化脚本 link镜像更新完后，可以查看文档中的版本介绍，通常需要执行升级脚本的版本都会标明需要初始化，打开对应的文档，参考说明执行初始化脚本即可，大部分时候都是需要发送一个POST请求。
QA link{{host}} 是什么 link{{}} 代表变量， {{host}}代表一个名为 host 的变量。指的是你服务器的域名或 IP。
Sealos 中，你可以在下图中找到你的域名：
如何获取 rootkey link从docker-compose.yml中的environment中获取，对应的是ROOT_KEY的值。
sealos 中可以从上图左侧的环境变量中获取。
如何跨版本升级！！ link建议逐一版本升级，防止脏数据。例如，当前版本是4.</description></item><item><title>Docker Mongo迁移(dump模式)</title><link>https://doc.tryfastgpt.ai/docs/development/migration/-docker_mongo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/migration/-docker_mongo/</guid><description>作者 linkhttps://github.com/samqin123
相关PR。有问题可打开这里与作者交流
介绍 link如何使用Mongodump来完成从A环境到B环境的Fastgpt的mongodb迁移
前提说明：
A环境：我在阿里云上部署的fastgpt，现在需要迁移到B环境。 B环境：是新环境比如腾讯云新部署的fastgpt，更特殊一点的是，NAS（群晖或者QNAP）部署了fastgpt，mongo必须改成4.2或者4.4版本（其实云端更方便，支持fastgpt mongo默认版本） C环境：妥善考虑，用本地电脑作为C环境过渡，保存相关文件并分离操作 ‍
1. 环境准备：进入 docker mongo 【A环境】 link docker exec -it mongo sh mongo -u &amp;#39;username&amp;#39; -p &amp;#39;password&amp;#39; &amp;gt;&amp;gt; show dbs 看到fastgpt数据库，以及其它几个，确定下导出数据库名称 准备： 检查数据库，容器和宿主机都创建一下 backup 目录 【A环境 + C环境】
准备： link检查数据库，容器和宿主机都创建一下“数据导出导入”临时目录 ，比如data/backup 【A环境建目录 + C环境建目录用于同步到容器中】
先在【A环境】创建文件目录，用于dump导出操作 link容器：（先进入fastgpt docker容器）
docker exec -it fastgpt sh mkdir -p /data/backup 建好后，未来导出mongo的数据，会在A环境本地fastgpt的安装目录/Data/下看到自动同步好的目录，数据会在data\backup中，然后可以衔接后续的压缩和下载转移动作。如果没有同步到本地，也可以手动建一下，配合docker cp 把文件拷到本地用（基本不会发生）
然后，【C环境】宿主机目录类似操作，用于把上传的文件自动同步到C环境部署的fastgpt容器里。 link到fastgpt目录，进入mongo目录，有data目录，下面建backup
mkdir -p /fastgpt/data/backup 准备好后，后续上传
### 新fastgpt环境【B】中也需要建一个，比如/fastgpt/mongobackup目录，注意不要在fastgpt/data目录下建立目录 mkdir -p /fastgpt/mongobackup
###2. 正题开始，从fastgpt老环境【A】中导出数据 进入A环境，使用mongodump 导出mongo数据库。 #### 2.</description></item><item><title>Docker 数据库迁移(无脑操作)</title><link>https://doc.tryfastgpt.ai/docs/development/migration/docker_db/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/migration/docker_db/</guid><description>Copy文件 linkDocker 部署数据库都会通过 volume 挂载本地的目录进入容器，如果要迁移，直接复制这些目录即可。
PG 数据: pg/data Mongo 数据: mongo/data</description></item><item><title>V4.8.11（进行中）</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/4811/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/4811/</guid><description>更新指南 link1. 做好数据备份 link V4.8.11 更新预告 link 新增 - 插件自定义输入支持单选框 新增 - 插件输出，支持指定某些字段为工具调用结果 新增 - 插件支持配置使用引导、全局变量和文件输入 优化 - SSE 响应代码。 优化 - 非 HTTPS 环境下支持复制（除非 textarea 复制也不支持）</description></item><item><title>V4.8.10（进行中）</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/4810/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/4810/</guid><description>更新指南 link1. 做好数据备份 link2. 商业版 —— 修改环境变量 link 需要给fastgpt-pro镜像，增加沙盒的环境变量：SANDBOX_URL=http://xxxxx:3000 给fastgpt-pro镜像和fastgpt镜像增加环境变量，以便更好的存储系统日志： LOG_LEVEL=debug STORE_LOG_LEVEL=warn 3. 修改镜像tag link 更新 FastGPT 镜像 tag: v4.8.10-alpha 更新 FastGPT 商业版镜像 tag: v4.8.10-alpha Sandbox 镜像，可以不更新 4. 执行初始化 link从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成FastGPT 域名。
curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv4810&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 初始化发布记录版本标记 初始化开票记录 V4.8.10 更新说明 link完整内容请见：4.8.10 release
新增 - 模板市场 新增 - 工作流节点拖动自动对齐吸附 新增 - 用户选择节点（Debug 模式暂未支持） 新增 - 工作流撤销和重做 新增 - 工作流本次编辑记录，取代自动保存 新增 - 工作流版本支持重命名 新增 - 应用调用迁移成单独节点，同时可以传递全局变量和用户的文件。 商业版新增 - 飞书机器人接入 商业版新增 - 公众号接入接入 商业版新增 - 自助开票申请 商业版新增 - SSO 定制 优化 - SSE 响应优化。 优化 - 无 SSL 证书情况下，优化复制。 优化 - 单选框打开后自动滚动到选中的位置。 优化 - 知识库集合禁用，目录禁用会递归修改其下所有 children 的禁用状态。 优化 - 节点选择，避免切换 tab 时候，path 加载报错。 优化 - 最新 React Markdown 组件，支持 Base64 图片。 优化 - 知识库列表 UI。 优化 - 支持无网络配置情况下运行。 优化 - 部分全局变量，增加数据类型约束。 修复 - 全局变量 key 可能重复。 修复 - Prompt 模式调用工具，stream=false 模式下，会携带 0: 开头标记。 修复 - 对话日志鉴权问题：仅为 APP 管理员的用户，无法查看对话日志详情。 修复 - 选择 Milvus 部署时，无法导出知识库。 修复 - 创建 APP 副本，无法复制系统配置。 修复 - 图片识别模式下，自动解析图片链接正则不够严谨问题。 修复 - 内容提取的数据类型与输出数据类型未一致。 修复 - 工作流运行时间统计错误。 修复 - stream 模式下，工具调用有可能出现 undefined 修复 - 全局变量在 API 中无法持久化。</description></item><item><title>V4.8.9（需要初始化）</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/489/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/489/</guid><description>升级指南 link1. 做好数据库备份 link2. 修改镜像 link 更新 FastGPT 镜像 tag: v4.8.9 更新 FastGPT 商业版镜像 tag: v4.8.9 Sandbox 镜像，可以不更新 3. 商业版执行初始化 link从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成FastGPT 商业版域名。
curl --location --request POST &amp;#39;https://{{host}}/api/admin/init/489&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 会初始化多租户的通知方式，仅内部使用的，无需执行。
V4.8.9 更新说明 link 新增 - 文件上传配置，不再依赖视觉模型决定是否可上传图片，而是通过系统配置决定。 新增 - AI 对话节点和工具调用支持选择“是否开启图片识别”，开启后会自动获取对话框上传的图片和“用户问题”中的图片链接。 新增 - 文档解析节点。 商业版新增 - 团队通知账号绑定，用于接收重要信息。 商业版新增 - 知识库集合标签功能，可以对知识库进行标签管理。 商业版新增 - 知识库搜索节点支持标签过滤和创建时间过滤。 商业版新增 - 转移 App owner 权限。 新增 - 删除所有对话引导内容。 新增 - QA 拆分支持自定义 chunk 大小，并优化 gpt4o-mini 拆分时，chunk 太大导致生成内容很少的问题。 优化 - 对话框信息懒加载，减少网络传输。 优化 - 清除选文件缓存，支持重复选择同一个文件。 修复 - 知识库上传文件，网络不稳定或文件较多情况下，进度无法到 100%。 修复 - 删除应用后回到聊天选择最后一次对话的应用为删除的应用时提示无该应用问题。 修复 - 插件动态变量配置默认值时，无法正常显示默认值。 修复 - 工具调用温度和最大回复值未生效。 修复 - 函数调用模式，assistant role 中，GPT 模型必须传入 content 参数。（不影响大部分模型，目前基本都改用用 ToolChoice 模式，FC 模式已弃用）。 修复 - 知识库文件上传进度更新可能异常。 修复 - 知识库 rebuilding 时候，页面总是刷新到第一页。 修复 - 知识库 list openapi 鉴权问题。 修复 - 分享链接，新对话无法反馈。</description></item><item><title>V4.8.8(需要初始化)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/488/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/488/</guid><description>升级指南 link1. 做好数据库备份 link2. 修改镜像 link fastgpt 镜像 tag 修改成 v4.8.8-fix2 商业版镜像 tag 修改成 v4.8.8 3. 执行初始化 link从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成FastGPT 域名。
curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv488&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 会初始化知识库的继承权限
V4.8.8 更新说明 link点击查看完整更新
新增 - 重构系统插件的结构。允许向开源社区 PR 系统插件，具体可见: 如何向 FastGPT 社区提交系统插件。 新增 - DuckDuckGo 系统插件。 新增 - 飞书 webhook 系统插件。 新增 - 修改变量填写方式。提示词输入框以以及工作流中所有 Textarea 输入框，支持输入 / 唤起变量选择，可直接选择所有上游输出值，无需动态引入。 商业版新增 - 知识库权限继承。 优化 - 移动端快速切换应用交互。 优化 - 节点图标。 优化 - 对话框引用增加额外复制案件，便于复制。增加引用内容折叠。 优化 - OpenAI sdk 升级，并自定义了 whisper 模型接口（未仔细查看 sdk 实现，但 sdk 中 whisper 接口，似乎无法适配一般 fastapi 接口） 修复 - Permission 表声明问题。 修复 - 并行执行节点，运行时间未正确记录。 修复 - 运行详情未正确展示嵌套节点信息。 修复 - 简易模式，首次进入，无法正确获取知识库配置。 修复 - Log debug level 配置无效。 修复 - 插件独立运行时，会将插件输入的值进行变量替换，可能导致后续节点变量异常。</description></item><item><title>V4.8.7</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/487/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/487/</guid><description>升级指南 link1. 做好数据库备份 link2. 修改镜像 link fastgpt 镜像 tag 修改成 v4.8.7 商业版镜像 tag 修改成 v4.8.7 V4.8.7 更新说明 link 新增 - 插件支持独立运行，发布和日志查看 新增 - 应用搜索 优化 - 对话框代码 优化 - 升级 Dockerfile node 和 pnpm 版本 优化 - local 域名部署，也可以正常使用 vision 模式 修复 - 简易模式无法变更全局变量 修复 - gpt4o 无法同时使用工具和图片</description></item><item><title>V4.8.6(需要初始化)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/486/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/486/</guid><description>升级指南 link1. 做好数据库备份 link2. 修改镜像 link fastgpt 镜像 tag 修改成 v4.8.6 fastgpt-sandbox 镜像 tag 修改成 v4.8.6 商业版镜像 tag 修改成 v4.8.6 3. 执行初始化 link从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成FastGPT 域名。
curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv486&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 会初始化应用的继承权限
V4.8.6 更新说明 link 新增 - 应用权限继承 新增 - 知识库支持单个集合禁用功能 新增 - 系统插件模式变更，新增链接读取和数学计算器插件，正式版会更新如何自定义系统插件 新增 - 代码沙盒运行参数 新增 - AI对话时隐藏头部的功能，主要是适配移动端 优化 - 文件读取，Mongo 默认使用从节点，减轻主节点压力 优化 - 提示词模板 优化 - Mongo model 重复加载 修复 - 创建链接集合未返回 id 修复 - 文档接口说明 修复 - api system 提示合并 修复 - 团队插件目录内的内容无法加载 修复 - 知识库集合目录面包屑无法加载 修复 - Markdown 导出对话异常 修复 - 提示模板结束标签错误 修复 - 文档描述</description></item><item><title>V4.8.5(需要初始化)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/485/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/485/</guid><description>升级指南 link1. 做好数据库备份 link2. 修改镜像 link fastgpt 镜像 tag 修改成 v4.8.5 商业版镜像 tag 修改成 v4.8.5 3. 执行初始化 link从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成FastGPT 域名。
curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv485&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 会把插件的数据表合并到应用中，插件表不会删除。
商业版用户执行额外的初始化
从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成FastGPT 商业版的域名：
curl --location --request POST &amp;#39;https://{{host}}/api/admin/init/485&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 会重置知识库权限系统。
V4.8.5 更新说明 link 新增 - 合并插件和应用，统一成工作台 新增 - 应用创建副本功能 新增 - 应用创建模板 新增 - 支持代码运行结果作为工具输出。 新增 - Markdown 图片输出，支持移动端放大缩放。 优化 - 原文件编码存取 优化 - 知识库删除后，简易模式会过滤掉删除的知识库，避免错误判断。 优化 - 文件夹读取，支持单个文件夹超出 100 个文件 优化 - 问答拆分/手动录入，当有a字段时，自动将q作为补充索引。 优化 - 对话框页面代码 优化 - 工作流新节点自动增加序号名 修复 - 定时任务无法实际关闭 修复 - 输入引导特殊字符导致正则报错 修复 - 文件包含特殊字符%，且为转义时会导致页面崩溃 修复 - 自定义输入选择知识库引用时页面崩溃</description></item><item><title>V4.8.4(需要初始化)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/484/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/484/</guid><description>升级指南 link1. 修改镜像 link fastgpt 镜像 tag 修改成 v4.8.4 fastgpt-sandbox 镜像 tag 修改成 v4.8.4 (选择性，无变更) 商业版镜像 tag 修改成 v4.8.4 2. 商业版用户执行初始化 link从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成FastGPT 商业版的域名。
curl --location --request POST &amp;#39;https://{{host}}/api/admin/init/484&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; V4.8.4 更新说明 link 新增 - 应用使用新权限系统。 新增 - 应用支持文件夹。 优化 - 文本分割增加连续换行、制表符清除，避免大文本性能问题。 重要修复 - 修复系统插件运行池数据污染问题，由于从内存获取，会导致全局污染。 修复 - Debug 模式下，相同 source 和 target 内容，导致连线显示异常。 修复 - 定时执行初始化错误。 修复 - 应用调用传参异常。 修复 - ctrl + cv 复杂节点时，nodeId错误。 调整组件库全局theme。</description></item><item><title>V4.8.3</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/483/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/483/</guid><description>升级指南 link fastgpt 镜像 tag 修改成 v4.8.3 fastgpt-sandbox 镜像 tag 修改成 v4.8.3 商业版镜像 tag 修改成 v4.8.3 V4.8.3 更新说明 link 新增 - 支持 Milvus 数据库， 可参考最新的 docker-compose-milvus.yml. 新增 - 给 chat 接口 empty answer 增加 log，便于排查模型问题。 新增 - ifelse判断器，字符串支持正则。 新增 - 代码运行支持 console.log 输出调试。 修复 - 变量更新在 Debug 模式下出错。</description></item><item><title>V4.8.2</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/482/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/482/</guid><description>Sealos 升级说明 link 在应用管理中新建一个应用，镜像为：registry.cn-hangzhou.aliyuncs.com/fastgpt/fastgpt-sandbox:v4.8.1 无需外网访问地址，端口号为3000 部署完后，复制应用的内网地址 点击变更`FastGPT - 修改环境变量，增加下面的环境变量即可 SANDBOX_URL=内网地址 Docker 部署 link可以拉取最新 docker-compose.yml 文件参考
新增一个容器 sandbox fastgpt 和 fastgpt-pro(商业版) 容器新增环境变量: SANDBOX_URL sandbox 简易不要开启外网访问，未做凭证校验。 V4.8.2 更新说明 link 新增 - js代码运行节点（更完整的type提醒，后续继续完善） 新增 - 内容提取节点支持数据类型选择 修复 - 新增的站点同步无法使用 修复 - 定时任务无法输入内容</description></item><item><title>V4.8.1(需要初始化)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/481/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/481/</guid><description>初始化脚本 link从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成FastGPT的域名。
curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv481&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 由于之前集合名不规范，该初始化会重置表名。请在初始化前，确保 dataset.trainings 表没有数据。 最好更新该版本时，暂停所有进行中业务，再进行初始化，避免数据冲突。
执行脏数据清理 link从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成FastGPT的域名。
curl --location --request POST &amp;#39;https://{{host}}/api/admin/clearInvalidData&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 初始化完后，可以执行这个命令。之前定时清理的定时器有些问题，部分数据没被清理，可以手动执行清理。
V4.8.1 更新说明 link使用 Chat api 接口需要注意，增加了 event: updateVariables 事件，用于更新变量。
点击查看升级说明</description></item><item><title>V4.8</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/48/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/48/</guid><description>新工作流 linkFastGPT workflow V2上线，支持更加简洁的工作流模式。
🤖
由于工作流差异较大，不少地方需要手动重新构建。请依次重建插件和应用
简易尽快更新工作流，避免未来持续迭代后导致无法兼容。
给应用和插件增加了 version 的字段，用于标识是旧工作流还是新工作流。当你更新 4.8 后，保存和新建的工作流均为新版，旧版工作流会有一个重置的弹窗提示。并且，如果是通过 API 和 分享链接 调用的工作流，仍可以正常使用，直到你下次保存它们。
商业版配置更新 link商业版用户如果配置了邮件验证码，需要在管理端 -&amp;gt; 项目配置 -&amp;gt; 登录配置 -&amp;gt; 邮箱登录配置 -&amp;gt; 修改 邮箱服务SMTP地址，之前只能配置别名，现在可以配置自定义的地址。下面是一组别名和实际地址关系：
qq: smtp.qq.com gmail: smtp.gmail.com
V4.8 更新说明 link 重构 - 工作流 新增 - 判断器。支持 if elseIf else 判断。 @newfish-cmyk （preview版本的if else节点需要删除重建） 新增 - 变量更新节点。支持更新运行中工作流输出变量，或更新全局变量。@newfish-cmyk 新增 - 工作流自动保存和版本管理。 新增 - 工作流 Debug 模式，可以调试单个节点或者逐步调试工作流。 新增 - 定时执行应用。可轻松实现定时任务。 新增 - 插件自定义输入优化，可以渲染输入组件。 新增 - 分享链接发送对话前 hook https://github.com/labring/FastGPT/pull/1252 @gaord 优化 - 工作流连线，可以四向连接，方便构建循环工作流。 优化 - 工作流上下文传递，性能🚀。 优化 - ctrl和alt+enter换行，换行符位置不正确。 优化 - chat中存储变量配置。避免修改变量后，影响旧的对话。 优化 - 简易模式，更新配置后自动更新调试框内容，无需保存。 优化 - worker进程管理，并将计算 Token 任务分配给 worker 进程。 优化 - 工具调用支持指定字段数据类型（string, boolean, number） https://github.</description></item><item><title>V4.7.1(需要初始化)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/471/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/471/</guid><description>初始化脚本 link从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成FastGPT的域名。
curl --location --request POST &amp;#39;https://{{host}}/api/admin/clearInvalidData&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 该请求会执行脏数据清理（清理无效的文件、清理无效的图片、清理无效的知识库集合、清理无效的向量）
修改配置文件 link增加了Laf环境配置：点击查看最新的配置文件
V4.7.1 更新说明 link 新增 - 语音输入完整配置。支持选择是否打开语音输入（包括分享页面），支持语音输入后自动发送，支持语音输入后自动语音播放（流式）。 新增 - pptx 和 xlsx 文件读取。但所有文件读取都放服务端，会消耗更多的服务器资源，以及无法在上传时预览更多内容。 新增 - 集成 Laf 云函数，可以读取 Laf 账号中的云函数作为 HTTP 模块。 新增 - 定时器，清理垃圾数据。（采用小范围清理，会清理最近n个小时的，所以请保证服务持续运行，长时间不允许，可以继续执行 clearInvalidData 的接口进行全量清理。） 商业版新增 - 后台配置系统通知。 优化 - 支持ip模式导出知识库。 修改 - csv导入模板，取消 header 校验，自动获取前两列。 修复 - 工具调用模块连线数据类型校验错误。 修复 - 自定义索引输入时，解构数据失败。 修复 - rerank 模型数据格式。 修复 - 问题补全历史记录BUG 修复 - 分享页面特殊情况下加载缓慢问题（由于ssr时候数据库不会触发连接）</description></item><item><title>V4.7（需要初始化）</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/47/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/47/</guid><description>1. 修改配置文件 link增加一些 Boolean 值，用于决定不同功能块可以使用哪些模型，同时增加了模型的 logo：点击查看最新的配置文件
2. 初始化脚本 link升级完镜像后。从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成自己域名
curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv47&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 脚本功能：
初始化插件的 parentId 3. 升级 ReRank 模型 link4.7对ReRank模型进行了格式变动，兼容 cohere 的格式，可以直接使用 cohere 提供的 API。如果是本地的 ReRank 模型，需要修改镜像为：registry.cn-hangzhou.aliyuncs.com/fastgpt/bge-rerank-base:v0.1 。
cohere的重排模型对中文不是很好，感觉不如 bge 的好用，接入教程如下：
申请 Cohere 官方 Key: https://dashboard.cohere.com/api-keys 修改 FastGPT 配置文件 { &amp;#34;reRankModels&amp;#34;: [ { &amp;#34;model&amp;#34;: &amp;#34;rerank-multilingual-v2.0&amp;#34;, // 这里的 model 需要对应 cohere 的模型名 &amp;#34;name&amp;#34;: &amp;#34;检索重排&amp;#34;, // 随意 &amp;#34;requestUrl&amp;#34;: &amp;#34;https://api.</description></item><item><title>V4.6.9(需要初始化)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/469/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/469/</guid><description>初始化脚本 link从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成自己域名
curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv469&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 重置计量表。 执行脏数据清理（清理无效的文件、清理无效的图片、清理无效的知识库集合、清理无效的向量） 外部接口更新 link 由于计费系统变更，分享链接对话上报接口需要做一些调整，price字段被totalPoints字段取代。inputToken和outputToken不再提供，只提供token字段（总token数量）。 V4.6.9 更新说明 link 商业版新增 - 知识库新增“增强处理”训练模式，可生成更多类型索引。 新增 - 完善了HTTP模块的变量提示。 新增 - HTTP模块支持OpenAI单接口导入。 新增 - 全局变量支持增加外部变量。可通过分享链接的Query或 API 的 variables 参数传入。 新增 - 内容提取模块增加默认值。 优化 - 问题补全。增加英文类型。同时可以设置为单独模块，方便复用。 优化 - 重写了计量模式 优化 - Token 过滤历史记录，保持偶数条，防止部分模型报错。 优化 - 分享链接SEO，可直接展示应用名和头像。 修复 - 标注功能。 修复 - qa生成线程计数错误。 修复 - 问题分类连线类型错误</description></item><item><title>V4.6.8（需要初始化）</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/468/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/468/</guid><description>docker 部署 - 手动更新 Mongo link 修改 docker-compose.yml 的mongo部分，补上command和entrypoint mongo: image: mongo:5.0.18 # image: registry.cn-hangzhou.aliyuncs.com/fastgpt/mongo:5.0.18 # 阿里云 container_name: mongo ports: - 27017:27017 networks: - fastgpt command: mongod --keyFile /data/mongodb.key --replSet rs0 environment: # 这里密码注意要和以前的一致 - MONGO_INITDB_ROOT_USERNAME=username - MONGO_INITDB_ROOT_PASSWORD=password volumes: - ./mongo/data:/data/db entrypoint: - bash - -c - | openssl rand -base64 128 &amp;gt; /data/mongodb.key chmod 400 /data/mongodb.key chown 999:999 /data/mongodb.key echo &amp;#39;const isInited = rs.status().ok === 1 if(!isInited){ rs.initiate({ _id: &amp;#34;rs0&amp;#34;, members: [ { _id: 0, host: &amp;#34;mongo:27017&amp;#34; } ] }) }&amp;#39; &amp;gt; /data/initReplicaSet.</description></item><item><title>V4.6.7（需要初始化）</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/467/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/467/</guid><description>1。执行初始化 API link发起 1 个 HTTP 请求 ({{rootkey}} 替换成环境变量里的 rootkey，{{host}} 替换成自己域名)
https://xxxxx/api/admin/initv467 curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv467&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 初始化说明：
将 images 重新关联到数据集 设置 pg 表的 null 值。 V4.6.7 更新说明 link 修改了知识库UI及新的导入交互方式。 优化知识库和对话的数据索引。 知识库 openAPI，支持通过 API 操作知识库。 新增 - 输入框变量提示。输入 { 号后将会获得可用变量提示。根据社区针对高级编排的反馈，我们计划于 2 月份的版本中，优化变量内容，支持模块的局部变量以及更多全局变量写入。 优化 - 切换团队后会保存记录，下次登录时优先登录该团队。 修复 - API 对话时，chatId 冲突问题。 修复 - Iframe 嵌入网页可能导致的 window.onLoad 冲突。</description></item><item><title>V4.6.6（需要改配置文件）</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/466/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/466/</guid><description>配置文件变更 link为了减少代码重复度，我们对配置文件做了一些修改：点击查看最新的配置文件
商业版变更 link 更新商业版镜像到 4.6.6 版本。
将旧版配置文件中的 SystemParams.pluginBaseUrl 放置到环境变量中:
PRO_URL=商业版镜像地址（此处不再需要以 /api 结尾），例如:
PRO_URL=http://fastgpt-plugin.ns-hsss5d.svc.cluster.local:3000
原本在配置文件中的 FeConfig 已被移除，可以直接打开新的商业版镜像外网地址进行配置。包括 FastGPT 的各个参数和模型都可以直接在商业版镜像中配置，无需再变更 config.json 文件。
V4.6.6 更新说明 link 查看 FastGPT 2024 RoadMap 新增 - Http 模块请求头支持 Json 编辑器。 新增 - ReRank模型部署 新增 - 搜索方式：分离向量语义检索，全文检索和重排，通过 RRF 进行排序合并。 优化 - 问题分类提示词，id引导。测试国产商用 api 模型（百度阿里智谱讯飞）使用 Prompt 模式均可分类。 UI 优化，未来将逐步替换新的UI设计。 优化代码：Icon 抽离和自动化获取。 修复 - 链接读取的数据集，未保存选择器，导致同步时不使用选择器。</description></item><item><title>V4.6.5（需要改配置文件）</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/465/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/465/</guid><description>配置文件变更 link由于 openai 已开始弃用 function call，改为 toolChoice。FastGPT 同步的修改了对于的配置和调用方式，需要对配置文件做一些修改：
点击查看最新的配置文件
主要是修改模型的functionCall字段，改成toolChoice即可。设置为true的模型，会默认走 openai 的 tools 模式；未设置或设置为false的，会走提示词生成模式。 问题优化模型与内容提取模型使用同一组配置。
增加 &amp;quot;ReRankModels&amp;quot;: [] V4.6.5 功能介绍 link 新增 - 问题优化模块 新增 - 文本编辑模块 新增 - 判断器模块 新增 - 自定义反馈模块 新增 - 【内容提取】模块支持选择模型，以及字段枚举 优化 - docx读取，兼容表格（表格转markdown） 优化 - 高级编排连接线交互 优化 - 由于 html2md 导致的 cpu密集计算，阻断线程问题 修复 - 高级编排提示词提取描述</description></item><item><title>V4.6.4(需要初始化)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/464/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/464/</guid><description>1。执行初始化 API link发起 1 个 HTTP 请求 ({{rootkey}} 替换成环境变量里的 rootkey，{{host}} 替换成自己域名)
https://xxxxx/api/admin/initv464 curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv464&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 初始化说明：
初始化 PG 的createTime字段 初始化 Mongo 中 chat 的 feedback 字段 V4.6.4 功能介绍 link 重写 - 分享链接身份逻辑，采用 localID 记录用户的ID。 商业版新增 - 分享链接 SSO 方案，通过身份鉴权地址，仅需3个接口即可完全接入已有用户系统。具体参考分享链接身份鉴权 新增 - 分享链接更多嵌入方式提示，更多DIY方式。 优化 - 历史记录模块。弃用旧的历史记录模块，直接在对应地方填写数值即可。 调整 - 知识库搜索模块 topk 逻辑，采用 MaxToken 计算，兼容不同长度的文本块 调整鉴权顺序，提高 apikey 的优先级，避免cookie抢占 apikey 的鉴权。 链接读取支持多选择器。参考Web 站点同步用法 修复 - 分享链接图片上传鉴权问题 修复 - Mongo 连接池未释放问题。 修复 - Dataset Intro 无法更新 修复 - md 代码块问题 修复 - root 权限问题 优化 docker file</description></item><item><title>V4.6.3(需要初始化)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/463/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/463/</guid><description>1。执行初始化 API link发起 1 个 HTTP 请求 ({{rootkey}} 替换成环境变量里的 rootkey，{{host}} 替换成自己域名)
https://xxxxx/api/admin/initv463 curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv463&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 初始化说明：
初始化Mongo 中 dataset，collection 和 data 的部分字段 V4.6.3 功能介绍 link 商业版新增 - web站点同步 新增 - 集合元数据记录 优化 - url 读取内容 优化 - 流读取文件，防止内存溢出 优化 - 4v模型自动将 url 转 base64，本地也可调试 优化 - 图片压缩等级 修复 - 图片压缩失败报错，防止文件读取过程卡死。</description></item><item><title>V4.6.2(需要初始化)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/462/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/462/</guid><description>1。执行初始化 API link发起 1 个 HTTP 请求 ({{rootkey}} 替换成环境变量里的 rootkey，{{host}} 替换成自己域名)
https://xxxxx/api/admin/initv462 curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv462&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 初始化说明：
初始化全文索引 V4.6.2 功能介绍 link 新增 - 全文索引（需配合 Rerank 模型，在看怎么放到开源版，模型接口比较特殊） 新增 - 插件来源（预计4.7/4.8版本会正式使用） 优化 - PDF读取 优化 - docx文件读取，转成 markdown 并保留其图片内容 修复和优化 TextSplitter 函数</description></item><item><title>V4.6.1</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/461/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/461/</guid><description>V4.6.1 功能介绍 link 新增 - GPT4-v 模型支持 新增 - whisper 语音输入 优化 - TTS 流传输 优化 - TTS 缓存</description></item><item><title>V4.6(需要初始化)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/46/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/46/</guid><description>V4.6 版本加入了简单的团队功能，可以邀请其他用户进来管理资源。该版本升级后无法执行旧的升级脚本，且无法回退。
1。更新镜像并变更配置文件 link更新镜像至 latest 或者 v4.6 版本。商业版镜像更新至 V0.2.1
最新配置可参考：V46 版本最新 config.json，商业镜像配置文件也更新，参考最新的飞书文档。
2。执行初始化 API link发起 2 个 HTTP 请求 ({{rootkey}} 替换成环境变量里的 rootkey，{{host}} 替换成自己域名)
该初始化接口可能速度很慢，返回超时不用管，注意看日志即可，需要注意的是，需确保 initv46 成功后，在执行 initv46-2
https://xxxxx/api/admin/initv46 curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv46&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; https://xxxxx/api/admin/initv46-2 curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv46-2&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 初始化内容： 1。创建默认团队 2。初始化 Mongo 所有资源的团队字段 3。初始化 Pg 的字段 4。初始化 Mongo Data
V4.6 功能介绍 link 新增 - 团队空间 新增 - 多路向量 (多个向量映射一组数据) 新增 - tts 语音 新增 - 支持知识库配置文本预处理模型 线上环境新增 - ReRank 向量召回，提高召回精度 优化 - 知识库导出，可直接触发流下载，无需等待转圈圈 4.</description></item><item><title>V4.5.2</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/452/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/452/</guid><description>功能介绍 linkFast GPT V4.5.2 link 新增 - 模块插件，允许自行组装插件进行模块复用。 优化 - 知识库引用提示。</description></item><item><title>V4.5.1(需进行初始化)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/451/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/451/</guid><description>执行初始化 API link发起 1 个 HTTP 请求（{{rootkey}} 替换成环境变量里的rootkey，{{host}}替换成自己域名）
https://xxxxx/api/admin/initv451 curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv451&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 初始化内容：
rename 数据库字段 初始化 Mongo APP 表中知识库的相关字段 初始化 PG 和 Mongo 的内容，为每个文件创建一个集合（存储 Mongo 中），并反馈赋值给 PG。 该初始化接口可能速度很慢，返回超时不用管，注意看日志即可
功能介绍 linkFast GPT V4.5.1 link 新增知识库文件夹管理 修复了 openai4.x sdk 无法兼容 oneapi 的智谱和阿里的接口。 修复部分模块无法触发完成事件</description></item><item><title>V4.5(需进行较为复杂更新)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/45/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/45/</guid><description>FastGPT V4.5 引入 PgVector0.5 版本的 HNSW 索引，极大的提高了知识库检索的速度，比起IVFFlat索引大致有3~10倍的性能提升，可轻松实现百万数据毫秒级搜索。缺点在于构建索引的速度非常慢，4c16g 500w 组数据使用并行构建大约花了 48 小时。具体参数配置可参考 PgVector官方
下面需要对数据库进行一些操作升级：
PgVector升级：Sealos 部署方案 link 点击Sealos桌面的数据库应用。 点击【pg】数据库的详情。 点击右上角的重启，等待重启完成。 点击左侧的一键链接，等待打开 Terminal。 依次输入下方 sql 命令 -- 升级插件名 ALTER EXTENSION vector UPDATE; -- 插件是否升级成功，成功的话，vector插件版本为 0.5.0，旧版的为 0.4.1 \dx -- 下面两个语句会设置 pg 在构建索引时可用的内存大小，需根据自身的数据库规格来动态配置，可配置为 1/4 的内存大小 alter system set maintenance_work_mem = &amp;#39;2400MB&amp;#39;; select pg_reload_conf(); -- 重构数据库索引和排序 REINDEX DATABASE postgres; -- 开始构建索引，该索引构建时间非常久，直接点击右上角的叉，退出 Terminal 即可 CREATE INDEX CONCURRENTLY vector_index ON modeldata USING hnsw (vector vector_ip_ops) WITH (m = 16, ef_construction = 64); -- 可以再次点击一键链接，进入 Terminal，输入下方命令，如果看到 &amp;#34;vector_index&amp;#34; hnsw (vector vector_ip_ops) WITH (m=&amp;#39;16&amp;#39;, ef_construction=&amp;#39;64&amp;#39;) 则代表构建完成（注意，后面没有 INVALID） \d modeldata PgVector升级：Docker-compose.</description></item><item><title>V4.4.7（需执行升级脚本）</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/447/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/447/</guid><description>执行初始化 API link发起 1 个 HTTP 请求（{{rootkey}} 替换成环境变量里的rootkey，{{host}}替换成自己域名）
https://xxxxx/api/admin/initv447 curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv447&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 初始化 pg 索引以及将 file_id 中空对象转成 manual 对象。如果数据多，可能需要较长时间，可以通过日志查看进度。
功能介绍 linkFast GPT V4.4.7 link 优化了数据库文件 crud。 兼容链接读取，作为 source。 区分手动录入和标注，可追数据至某个文件。 升级 openai sdk。</description></item><item><title>V4.4.6</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/446/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/446/</guid><description>功能介绍 link 高级编排新增模块 - 应用调用，可调用其他应用。 新增 - 必要连接校验 修复 - 下一步指引在免登录中身份问题。</description></item><item><title>V4.4.5(需要初始化)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/445/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/445/</guid><description>执行初始化 API link发起 1 个 HTTP 请求（记得携带 headers.rootkey，这个值是环境变量里的）
https://xxxxx/api/admin/initv445 curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv445&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 初始化了 variable 模块，将其合并到用户引导模块中。
功能介绍 linkFast GPT V4.4.5 link 新增 - 下一步指引选项，可以通过模型生成 3 个预测问题。 商业版新增 - 分享链接限制及 hook 身份校验（可对接已有的用户系统）。 商业版新增 - Api Key 使用。增加别名、额度限制和过期时间。自带 appId，无需额外连接。 优化 - 全局变量与开场白合并成同一模块。</description></item><item><title>升级到 V4.4.2(需要初始化)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/442/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/442/</guid><description>执行初始化 API link发起 1 个 HTTP 请求 (记得携带 headers.rootkey，这个值是环境变量里的)
https://xxxxx/api/admin/initv442 curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv442&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 会给初始化 Mongo 的 Bill 表的索引，之前过期时间有误。</description></item><item><title>升级到 V4.4.1(需要初始化)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/441/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/441/</guid><description>执行初始化 API link发起 1 个 HTTP 请求（记得携带 headers.rootkey，这个值是环境变量里的）
https://xxxxx/api/admin/initv441 curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv441&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 会给初始化 Mongo 的 dataset.files，将所有数据设置为可用。</description></item><item><title>升级到 V4.4(需要初始化)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/44/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/44/</guid><description>执行初始化 API link发起 1 个 HTTP 请求 (记得携带 headers.rootkey，这个值是环境变量里的)
https://xxxxx/api/admin/initv44 curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv44&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 会给初始化 Mongo 的部分字段。</description></item><item><title>升级到 V4.3(需要初始化)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/43/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/43/</guid><description>执行初始化 API link发起 1 个 HTTP 请求 (记得携带 headers.rootkey，这个值是环境变量里的)
https://xxxxx/api/admin/initv43 curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv43&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 会给 PG 数据库的 modeldata 表插入一个新列 file_id，用于存储文件 ID。
增加环境变量 link增加一个 FILE_TOKEN_KEY 环境变量，用于生成文件预览链接，过期时间为 30 分钟。
FILE_TOKEN_KEY=filetokenkey</description></item><item><title>升级到 V4.2.1</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/421/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/421/</guid><description>私有部署，如果添加了配置文件，需要在配置文件中修改 VectorModels 字段。增加 defaultToken 和 maxToken，分别对应直接分段时的默认 token 数量和该模型支持的 token 上限 (通常不建议超过 3000)
&amp;#34;VectorModels&amp;#34;: [ { &amp;#34;model&amp;#34;: &amp;#34;text-embedding-ada-002&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Embedding-2&amp;#34;, &amp;#34;price&amp;#34;: 0, &amp;#34;defaultToken&amp;#34;: 500, &amp;#34;maxToken&amp;#34;: 3000 } ] 改动目的是，我们认为不需要留有选择余地，选择一个最合适的模型去进行任务即可。</description></item><item><title>升级到 V4.2</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/42/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/42/</guid><description>99.9%用户不影响，升级 4.2 主要是修改了配置文件中 QAModel 的格式。从原先的数组改成对象：
&amp;#34;QAModel&amp;#34;: { &amp;#34;model&amp;#34;: &amp;#34;gpt-3.5-turbo-16k&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;GPT35-16k&amp;#34;, &amp;#34;maxToken&amp;#34;: 16000, &amp;#34;price&amp;#34;: 0 } 改动目的是，我们认为不需要留有选择余地，选择一个最合适的模型去进行任务即可。</description></item><item><title>升级到 V4.1</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/41/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/41/</guid><description>如果您是从旧版本升级到 V4.1，由于新版重新设置了对话存储结构，需要初始化原来的存储内容。
更新环境变量 linkV4.1 优化了 PostgreSQL 和 MongoDB 的连接变量，只需要填 1 个 URL 即可：
注意：/fastgpt 和 /postgres 是指数据库名称，需要和旧版的变量对应。
# mongo 配置，不需要改. 如果连不上，可能需要去掉 ?authSource=admin - MONGODB_URI=mongodb://username:password@mongo:27017/fastgpt?authSource=admin # pg配置. 不需要改 - PG_URL=postgresql://username:password@pg:5432/postgres 初始化 API link部署新版项目，并发起 1 个 HTTP 请求（记得携带 headers.rootkey，这个值是环境变量里的）
https://xxxxx/api/admin/initChatItem</description></item><item><title>升级到 V4.0</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/40/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/40/</guid><description>如果您是从旧版本升级到 V4，由于新版 MongoDB 表变更比较大，需要按照本文档的说明执行一些初始化脚本。
重命名表名 link需要连接上 MongoDB 数据库，执行两条命令：
db.models.renameCollection(&amp;#34;apps&amp;#34;) db.sharechats.renameCollection(&amp;#34;outlinks&amp;#34;) warning 注意：从旧版更新到 V4， MongoDB 会自动创建空表，你需要先手动删除这两个空表，再执行上面的操作。
初始化几个表中的字段 link依次执行下面 3 条命令，时间比较长，不成功可以重复执行（会跳过已经初始化的数据），直到所有数据更新完成。
db.chats.find({appId: {$exists: false}}).forEach(function(item){ db.chats.updateOne( { _id: item._id, }, { &amp;#34;$set&amp;#34;: {&amp;#34;appId&amp;#34;:item.modelId}} ) }) db.collections.find({appId: {$exists: false}}).forEach(function(item){ db.collections.updateOne( { _id: item._id, }, { &amp;#34;$set&amp;#34;: {&amp;#34;appId&amp;#34;:item.modelId}} ) }) db.outlinks.find({shareId: {$exists: false}}).forEach(function(item){ db.outlinks.updateOne( { _id: item._id, }, { &amp;#34;$set&amp;#34;: {&amp;#34;shareId&amp;#34;:item._id.toString(),&amp;#34;appId&amp;#34;:item.modelId}} ) }) 初始化 API link部署新版项目，并发起 3 个 HTTP 请求（记得携带 headers.rootkey，这个值是环境变量里的）
https://xxxxx/api/admin/initv4 https://xxxxx/api/admin/initChat https://xxxxx/api/admin/initOutlink 1 和 2 有可能会因为内存不足挂掉，可以重复执行。</description></item><item><title>Api Key 使用与鉴权</title><link>https://doc.tryfastgpt.ai/docs/development/openapi/auth/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/openapi/auth/</guid><description>使用说明 linkFasGPT OpenAPI 接口允许你使用 Api Key 进行鉴权，从而操作 FastGPT 上的相关服务和资源，例如：调用应用对话接口、上传知识库数据、搜索测试等等。出于兼容性和安全考虑，并不是所有的接口都允许通过 Api Key 访问。
如何查看 BaseURL link注意：BaseURL 不是接口地址，而是所有接口的根地址，直接请求 BaseURL 是没有用的。
如何获取 Api Key linkFastGPT 的 API Key 有 2 类，一类是全局通用的 key (无法直接调用应用对话)；一类是携带了 AppId 也就是有应用标记的 key (可直接调用应用对话)。
我们建议，仅操作应用或者对话的相关接口使用 应用特定key，其他接口使用 通用key。
通用key 应用特定 key 基本配置 linkOpenAPI 中，所有的接口都通过 Header.Authorization 进行鉴权。
baseUrl: &amp;#34;https://api.fastgpt.in/api&amp;#34; headers: { Authorization: &amp;#34;Bearer {{apikey}}&amp;#34; } 发起应用对话示例
curl --location --request POST &amp;#39;https://api.fastgpt.in/api/v1/chat/completions&amp;#39; \ --header &amp;#39;Authorization: Bearer fastgpt-xxxxxx&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; \ --data-raw &amp;#39;{ &amp;#34;chatId&amp;#34;: &amp;#34;111&amp;#34;, &amp;#34;stream&amp;#34;: false, &amp;#34;detail&amp;#34;: false, &amp;#34;messages&amp;#34;: [ { &amp;#34;content&amp;#34;: &amp;#34;导演是谁&amp;#34;, &amp;#34;role&amp;#34;: &amp;#34;user&amp;#34; } ] }&amp;#39;</description></item><item><title>对话接口</title><link>https://doc.tryfastgpt.ai/docs/development/openapi/chat/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/openapi/chat/</guid><description>🤖
该接口的 API Key 需使用应用特定的 key，否则会报错。
有些包调用时，BaseUrl需要添加v1路径，有些不需要，如果出现404情况，可补充v1重试。
发起对话(简易应用和工作流) link对话接口兼容GPT的接口！如果你的项目使用的是标准的GPT官方接口，可以直接通过修改BaseUrl和 Authorization来访问 FastGpt 应用，不过需要注意下面几个规则：
🤖
传入的model，temperature等参数字段均无效，这些字段由编排决定，不会根据 API 参数改变。
不会返回实际消耗Token值，如果需要，可以设置detail=true，并手动计算 responseData 里的tokens值。
请求 link 请求示例 参数说明 curl --location --request POST &amp;#39;https://api.fastgpt.in/api/v1/chat/completions&amp;#39; \ --header &amp;#39;Authorization: Bearer fastgpt-xxxxxx&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; \ --data-raw &amp;#39;{ &amp;#34;chatId&amp;#34;: &amp;#34;abcd&amp;#34;, &amp;#34;stream&amp;#34;: false, &amp;#34;detail&amp;#34;: false, &amp;#34;variables&amp;#34;: { &amp;#34;uid&amp;#34;: &amp;#34;asdfadsfasfd2323&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;张三&amp;#34; }, &amp;#34;messages&amp;#34;: [ { &amp;#34;content&amp;#34;: &amp;#34;导演是谁&amp;#34;, &amp;#34;role&amp;#34;: &amp;#34;user&amp;#34; } ] }&amp;#39; info headers.Authorization: Bearer {{apikey}} chatId: string | undefined 。 为 undefined 时（不传入），不使用 FastGpt 提供的上下文功能，完全通过传入的 messages 构建上下文。 不会将你的记录存储到数据库中，你也无法在记录汇总中查阅到。 为非空字符串时，意味着使用 chatId 进行对话，自动从 FastGpt 数据库取历史记录，并使用 messages 数组最后一个内容作为用户问题。请自行确保 chatId 唯一，长度小于250，通常可以是自己系统的对话框ID。 messages: 结构与 GPT接口 chat模式一致。 detail: 是否返回中间值（模块状态，响应的完整结果等），stream模式下会通过event进行区分，非stream模式结果保存在responseData中。 variables: 模块变量，一个对象，会替换模块中，输入框内容里的{{key}} 响应 link detail=false,stream=false 响应 detail=false,stream=true 响应 detail=true,stream=false 响应 detail=true,stream=true 响应 event值 { &amp;#34;id&amp;#34;: &amp;#34;adsfasf&amp;#34;, &amp;#34;model&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;usage&amp;#34;: { &amp;#34;prompt_tokens&amp;#34;: 1, &amp;#34;completion_tokens&amp;#34;: 1, &amp;#34;total_tokens&amp;#34;: 1 }, &amp;#34;choices&amp;#34;: [ { &amp;#34;message&amp;#34;: { &amp;#34;role&amp;#34;: &amp;#34;assistant&amp;#34;, &amp;#34;content&amp;#34;: &amp;#34;电影《铃芽之旅》的导演是新海诚。&amp;#34; }, &amp;#34;finish_reason&amp;#34;: &amp;#34;stop&amp;#34;, &amp;#34;index&amp;#34;: 0 } ] } data: {&amp;#34;id&amp;#34;:&amp;#34;&amp;#34;,&amp;#34;object&amp;#34;:&amp;#34;&amp;#34;,&amp;#34;created&amp;#34;:0,&amp;#34;choices&amp;#34;:[{&amp;#34;delta&amp;#34;:{&amp;#34;content&amp;#34;:&amp;#34;&amp;#34;},&amp;#34;index&amp;#34;:0,&amp;#34;finish_reason&amp;#34;:null}]} data: {&amp;#34;id&amp;#34;:&amp;#34;&amp;#34;,&amp;#34;object&amp;#34;:&amp;#34;&amp;#34;,&amp;#34;created&amp;#34;:0,&amp;#34;choices&amp;#34;:[{&amp;#34;delta&amp;#34;:{&amp;#34;content&amp;#34;:&amp;#34;电&amp;#34;},&amp;#34;index&amp;#34;:0,&amp;#34;finish_reason&amp;#34;:null}]} data: {&amp;#34;id&amp;#34;:&amp;#34;&amp;#34;,&amp;#34;object&amp;#34;:&amp;#34;&amp;#34;,&amp;#34;created&amp;#34;:0,&amp;#34;choices&amp;#34;:[{&amp;#34;delta&amp;#34;:{&amp;#34;content&amp;#34;:&amp;#34;影&amp;#34;},&amp;#34;index&amp;#34;:0,&amp;#34;finish_reason&amp;#34;:null}]} data: {&amp;#34;id&amp;#34;:&amp;#34;&amp;#34;,&amp;#34;object&amp;#34;:&amp;#34;&amp;#34;,&amp;#34;created&amp;#34;:0,&amp;#34;choices&amp;#34;:[{&amp;#34;delta&amp;#34;:{&amp;#34;content&amp;#34;:&amp;#34;《&amp;#34;},&amp;#34;index&amp;#34;:0,&amp;#34;finish_reason&amp;#34;:null}]} { &amp;#34;responseData&amp;#34;: [ // 不同模块的响应值, 不同版本具体值可能有差异，可先 log 自行查看最新值。 { &amp;#34;moduleName&amp;#34;: &amp;#34;Dataset Search&amp;#34;, &amp;#34;price&amp;#34;: 1.</description></item><item><title>知识库接口</title><link>https://doc.tryfastgpt.ai/docs/development/openapi/dataset/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/openapi/dataset/</guid><description>如何获取知识库ID（datasetId） 如何获取文件集合ID（collection_id） 创建训练订单 link 请求示例 响应示例 新例子
curl --location --request POST &amp;#39;https://api.fastgpt.in/api/support/wallet/usage/createTrainingUsage&amp;#39; \ --header &amp;#39;Authorization: Bearer {{apikey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; \ --data-raw &amp;#39;{ &amp;#34;datasetId&amp;#34;: &amp;#34;知识库 ID&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;可选，自定义订单名称，例如：文档训练-fastgpt.docx&amp;#34; }&amp;#39; x例子
curl --location --request POST &amp;#39;https://api.fastgpt.in/api/support/wallet/bill/createTrainingBill&amp;#39; \ --header &amp;#39;Authorization: Bearer {{apikey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; \ --data-raw &amp;#39;{ &amp;#34;name&amp;#34;: &amp;#34;可选，自定义订单名称，例如：文档训练-fastgpt.docx&amp;#34; }&amp;#39; data 为 billId，可用于添加知识库数据时进行账单聚合。
{ &amp;#34;code&amp;#34;: 200, &amp;#34;statusText&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;message&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;data&amp;#34;: &amp;#34;65112ab717c32018f4156361&amp;#34; } 知识库 link创建一个知识库 link 请求示例 参数说明 响应示例 curl --location --request POST &amp;#39;http://localhost:3000/api/core/dataset/create&amp;#39; \ --header &amp;#39;Authorization: Bearer {{authorization}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; \ --data-raw &amp;#39;{ &amp;#34;parentId&amp;#34;: null, &amp;#34;type&amp;#34;: &amp;#34;dataset&amp;#34;, &amp;#34;name&amp;#34;:&amp;#34;测试&amp;#34;, &amp;#34;intro&amp;#34;:&amp;#34;介绍&amp;#34;, &amp;#34;avatar&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;vectorModel&amp;#34;: &amp;#34;text-embedding-ada-002&amp;#34;, &amp;#34;agentModel&amp;#34;: &amp;#34;gpt-3.</description></item><item><title>分享链接身份鉴权</title><link>https://doc.tryfastgpt.ai/docs/development/openapi/share/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/openapi/share/</guid><description>介绍 link在 FastGPT V4.6.4 中，我们修改了分享链接的数据读取方式，为每个用户生成一个 localId，用于标识用户，从云端拉取对话记录。但是这种方式仅能保障用户在同一设备同一浏览器中使用，如果切换设备或者清空浏览器缓存则会丢失这些记录。这种方式存在一定的风险，因此我们仅允许用户拉取近30天的20条记录。
分享链接身份鉴权设计的目的在于，将 FastGPT 的对话框快速、安全的接入到你现有的系统中，仅需 2 个接口即可实现。
使用说明 link免登录链接配置中，你可以选择填写身份验证栏。这是一个POST请求的根地址。在填写该地址后，分享链接的初始化、开始对话以及对话结束都会向该地址的特定接口发送一条请求。下面以host来表示凭身份验证根地址。服务器接口仅需返回是否校验成功即可，不需要返回其他数据，格式如下：
接口统一响应格式 link { &amp;#34;success&amp;#34;: true, &amp;#34;message&amp;#34;: &amp;#34;错误提示&amp;#34;, &amp;#34;msg&amp;#34;: &amp;#34;同message, 错误提示&amp;#34;, &amp;#34;data&amp;#34;: { &amp;#34;uid&amp;#34;: &amp;#34;用户唯一凭证&amp;#34; } } FastGPT 将会判断success是否为true决定是允许用户继续操作。message与msg是等同的，你可以选择返回其中一个，当success不为true时，将会提示这个错误。
uid是用户的唯一凭证，将会用于拉取对话记录以及保存对话记录。可参考下方实践案例。
触发流程 link 配置教程 link1. 配置身份校验地址 link 配置校验地址后，在每次分享链接使用时，都会向对应的地址发起校验和上报请求。
🤖
这里仅需配置根地址，无需具体到完整请求路径。
2. 分享链接中增加额外 query link在分享链接的地址中，增加一个额外的参数: authToken。例如：
原始的链接：https://share.fastgpt.in/chat/share?shareId=648aaf5ae121349a16d62192
完整链接: https://share.fastgpt.in/chat/share?shareId=648aaf5ae121349a16d62192&amp;amp;authToken=userid12345
这个authToken通常是你系统生成的用户唯一凭证（Token之类的）。FastGPT 会在鉴权接口的body中携带 token={{authToken}} 的参数。
3. 编写聊天初始化校验接口 link 请求示例 鉴权成功 鉴权失败 curl --location --request POST &amp;#39;{{host}}/shareAuth/init&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; \ --data-raw &amp;#39;{ &amp;#34;token&amp;#34;: &amp;#34;{{authToken}}&amp;#34; }&amp;#39; { &amp;#34;success&amp;#34;: true, &amp;#34;data&amp;#34;: { &amp;#34;uid&amp;#34;: &amp;#34;用户唯一凭证&amp;#34; } } 系统会拉取该分享链接下，uid 为 username123 的对话记录。</description></item><item><title>使用 Xinference 接入本地模型</title><link>https://doc.tryfastgpt.ai/docs/development/custom-models/xinference/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/custom-models/xinference/</guid><description>Xinference 是一款开源模型推理平台，除了支持 LLM，它还可以部署 Embedding 和 ReRank 模型，这在企业级 RAG 构建中非常关键。同时，Xinference 还提供 Function Calling 等高级功能。还支持分布式部署，也就是说，随着未来应用调用量的增长，它可以进行水平扩展。
安装 Xinference linkXinference 支持多种推理引擎作为后端，以满足不同场景下部署大模型的需要，下面会分使用场景来介绍一下这三种推理后端，以及他们的使用方法。
1. 服务器 link如果你的目标是在一台 Linux 或者 Window 服务器上部署大模型，可以选择 Transformers 或 vLLM 作为 Xinference 的推理后端：
Transformers：通过集成 Huggingface 的 Transformers 库作为后端，Xinference 可以最快地 集成当今自然语言处理（NLP）领域的最前沿模型（自然也包括 LLM）。 vLLM: vLLM 是由加州大学伯克利分校开发的一个开源库，专为高效服务大型语言模型（LLM）而设计。它引入了 PagedAttention 算法， 通过有效管理注意力键和值来改善内存管理，吞吐量能够达到 Transformers 的 24 倍，因此 vLLM 适合在生产环境中使用，应对高并发的用户访问。 假设你服务器配备 NVIDIA 显卡，可以参考这篇文章中的指令来安装 CUDA，从而让 Xinference 最大限度地利用显卡的加速功能。
Docker 部署 link你可以使用 Xinference 官方的 Docker 镜像来一键安装和启动 Xinference 服务（确保你的机器上已经安装了 Docker），命令如下：
docker run -p 9997:9997 --gpus all xprobe/xinference:latest xinference-local -H 0.</description></item><item><title>接入 bge-rerank 重排模型</title><link>https://doc.tryfastgpt.ai/docs/development/custom-models/bge-rerank/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/custom-models/bge-rerank/</guid><description>不同模型推荐配置 link推荐配置如下：
模型名 内存 显存 硬盘空间 启动命令 bge-reranker-base &amp;gt;=4GB &amp;gt;=4GB &amp;gt;=8GB python app.py bge-reranker-large &amp;gt;=8GB &amp;gt;=8GB &amp;gt;=8GB python app.py bge-reranker-v2-m3 &amp;gt;=8GB &amp;gt;=8GB &amp;gt;=8GB python app.py 源码部署 link1. 安装环境 link Python 3.9, 3.10 CUDA 11.7 科学上网环境 2. 下载代码 link3 个模型代码分别为：
https://github.com/labring/FastGPT/tree/main/python/bge-rerank/bge-reranker-base https://github.com/labring/FastGPT/tree/main/python/bge-rerank/bge-reranker-large https://github.com/labring/FastGPT/tree/main/python/bge-rerank/bge-reranker-v2-m3 3. 安装依赖 link pip install -r requirements.txt 4. 下载模型 link3个模型的 huggingface 仓库地址如下：
https://huggingface.co/BAAI/bge-reranker-base https://huggingface.co/BAAI/bge-reranker-large https://huggingface.co/BAAI/bge-reranker-v2-m3 在对应代码目录下 clone 模型。目录结构：
bge-reranker-base/ app.py Dockerfile requirements.txt 5. 运行代码 link python app.py 启动成功后应该会显示如下地址：</description></item><item><title>接入 ChatGLM2-6B</title><link>https://doc.tryfastgpt.ai/docs/development/custom-models/chatglm2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/custom-models/chatglm2/</guid><description>前言 linkFastGPT 允许你使用自己的 OpenAI API KEY 来快速调用 OpenAI 接口，目前集成了 GPT-3.5, GPT-4 和 embedding，可构建自己的知识库。但考虑到数据安全的问题，我们并不能将所有的数据都交付给云端大模型。
那么如何在 FastGPT 上接入私有化模型呢？本文就以清华的 ChatGLM2 为例，为各位讲解如何在 FastGPT 中接入私有化模型。
ChatGLM2-6B 简介 linkChatGLM2-6B 是开源中英双语对话模型 ChatGLM-6B 的第二代版本，具体介绍可参阅 ChatGLM2-6B 项目主页。
warning 注意，ChatGLM2-6B 权重对学术研究完全开放，在获得官方的书面许可后，亦允许商业使用。本教程只是介绍了一种用法，无权给予任何授权！
推荐配置 link依据官方数据，同样是生成 8192 长度，量化等级为 FP16 要占用 12.8GB 显存、int8 为 8.1GB 显存、int4 为 5.1GB 显存，量化后会稍微影响性能，但不多。
因此推荐配置如下：
类型 内存 显存 硬盘空间 启动命令 fp16 &amp;gt;=16GB &amp;gt;=16GB &amp;gt;=25GB python openai_api.py 16 int8 &amp;gt;=16GB &amp;gt;=9GB &amp;gt;=25GB python openai_api.py 8 int4 &amp;gt;=16GB &amp;gt;=6GB &amp;gt;=25GB python openai_api.</description></item><item><title>接入 M3E 向量模型</title><link>https://doc.tryfastgpt.ai/docs/development/custom-models/m3e/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/custom-models/m3e/</guid><description>前言 linkFastGPT 默认使用了 openai 的 embedding 向量模型，如果你想私有部署的话，可以使用 M3E 向量模型进行替换。M3E 向量模型属于小模型，资源使用不高，CPU 也可以运行。下面教程是基于 “睡大觉” 同学提供的一个的镜像。
部署镜像 link镜像名: stawky/m3e-large-api:latest
国内镜像： registry.cn-hangzhou.aliyuncs.com/fastgpt_docker/m3e-large-api:latest 端口号: 6008 环境变量：
# 设置安全凭证（即oneapi中的渠道密钥） 默认值：sk-aaabbbcccdddeeefffggghhhiiijjjkkk 也可以通过环境变量引入：sk-key。有关docker环境变量引入的方法请自寻教程，此处不再赘述。 接入 One API link添加一个渠道，参数如下：
测试 linkcurl 例子：
curl --location --request POST &amp;#39;https://domain/v1/embeddings&amp;#39; \ --header &amp;#39;Authorization: Bearer xxxx&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; \ --data-raw &amp;#39;{ &amp;#34;model&amp;#34;: &amp;#34;m3e&amp;#34;, &amp;#34;input&amp;#34;: [&amp;#34;laf是什么&amp;#34;] }&amp;#39; Authorization 为 sk-key。model 为刚刚在 One API 填写的自定义模型。
接入 FastGPT link修改 config.json 配置文件，在 vectorModels 中加入 M3E 模型：</description></item><item><title>接入 ChatGLM2-m3e 模型</title><link>https://doc.tryfastgpt.ai/docs/development/custom-models/chatglm2-m3e/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/custom-models/chatglm2-m3e/</guid><description>前言 linkFastGPT 默认使用了 OpenAI 的 LLM 模型和向量模型，如果想要私有化部署的话，可以使用 ChatGLM2 和 m3e-large 模型。以下是由用户@不做了睡大觉 提供的接入方法。该镜像直接集成了 M3E-Large 和 ChatGLM2-6B 模型，可以直接使用。
部署镜像 link 镜像名: stawky/chatglm2-m3e:latest 国内镜像名: registry.cn-hangzhou.aliyuncs.com/fastgpt_docker/chatglm2-m3e:latest 端口号: 6006 # 设置安全凭证（即oneapi中的渠道密钥）
默认值：sk-aaabbbcccdddeeefffggghhhiiijjjkkk
也可以通过环境变量引入：sk-key。有关docker环境变量引入的方法请自寻教程，此处不再赘述。 接入 One API link为 chatglm2 和 m3e-large 各添加一个渠道，参数如下：
这里我填入 m3e 作为向量模型，chatglm2 作为语言模型
测试 linkcurl 例子：
curl --location --request POST &amp;#39;https://domain/v1/embeddings&amp;#39; \
--header &amp;#39;Authorization: Bearer sk-aaabbbcccdddeeefffggghhhiiijjjkkk&amp;#39; \
--header &amp;#39;Content-Type: application/json&amp;#39; \
--data-raw &amp;#39;{
&amp;#34;model&amp;#34;: &amp;#34;m3e&amp;#34;,
&amp;#34;input&amp;#34;: [&amp;#34;laf是什么&amp;#34;]
}&amp;#39; curl --location --request POST &amp;#39;https://domain/v1/chat/completions&amp;#39; \
--header &amp;#39;Authorization: Bearer sk-aaabbbcccdddeeefffggghhhiiijjjkkk&amp;#39; \
--header &amp;#39;Content-Type: application/json&amp;#39; \
--data-raw &amp;#39;{
&amp;#34;model&amp;#34;: &amp;#34;chatglm2&amp;#34;,
&amp;#34;messages&amp;#34;: [{&amp;#34;role&amp;#34;: &amp;#34;user&amp;#34;, &amp;#34;content&amp;#34;: &amp;#34;Hello!</description></item><item><title>Nginx 中转</title><link>https://doc.tryfastgpt.ai/docs/development/proxy/nginx/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/proxy/nginx/</guid><description>登录 Sealos linkSealos
创建应用 link打开 「应用管理」，点击「新建应用」：
填写基本配置 link务必开启外网访问，复制外网访问提供的地址。
添加配置文件 link 复制下面这段配置文件，注意 server_name 后面的内容替换成第二步的外网访问地址。
user nginx; worker_processes auto; worker_rlimit_nofile 51200; events { worker_connections 1024; } http { resolver 8.8.8.8; proxy_ssl_server_name on; access_log off; server_names_hash_bucket_size 512; client_header_buffer_size 64k; large_client_header_buffers 4 64k; client_max_body_size 50M; proxy_connect_timeout 240s; proxy_read_timeout 240s; proxy_buffer_size 128k; proxy_buffers 4 256k; server { listen 80; server_name tgohwtdlrmer.cloud.sealos.io; # 这个地方替换成 Sealos 提供的外网地址 location ~ /openai/(.*) { proxy_pass https://api.openai.com/$1$is_args$args; proxy_set_header Host api.openai.com; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # 如果响应是流式的 proxy_set_header Connection &amp;#39;&amp;#39;; proxy_http_version 1.</description></item><item><title>HTTP 代理中转</title><link>https://doc.tryfastgpt.ai/docs/development/proxy/http_proxy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/proxy/http_proxy/</guid><description>如果你有代理工具（例如 Clash 或者 sing-box），也可以使用 HTTP 代理来访问 OpenAI。只需要添加以下两个环境变量即可：
AXIOS_PROXY_HOST= AXIOS_PROXY_PORT= 以 Clash 为例，建议指定 api.openai.com 走代理，其他请求都直连。示例配置如下：
mixed-port: 7890 allow-lan: false bind-address: &amp;#39;*&amp;#39; mode: rule log-level: warning dns: enable: true ipv6: false nameserver: - 8.8.8.8 - 8.8.4.4 cache-size: 400 proxies: - proxy-groups: - { name: &amp;#39;♻️ 自动选择&amp;#39;, type: url-test, proxies: [香港V01×1.5], url: &amp;#39;https://api.openai.com&amp;#39;, interval: 3600} rules: - &amp;#39;DOMAIN-SUFFIX,api.openai.com,♻️ 自动选择&amp;#39; - &amp;#39;MATCH,DIRECT&amp;#39; 然后给 FastGPT 添加两个环境变量：
AXIOS_PROXY_HOST=127.0.0.1 AXIOS_PROXY_PORT=7890</description></item><item><title>Cloudflare Worker 中转</title><link>https://doc.tryfastgpt.ai/docs/development/proxy/cloudflare/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/proxy/cloudflare/</guid><description>参考 &amp;ldquo;不做了睡觉&amp;rdquo; 的教程
workers 配置文件
const TELEGRAPH_URL = &amp;#39;https://api.openai.com&amp;#39;; addEventListener(&amp;#39;fetch&amp;#39;, (event) =&amp;gt; { event.respondWith(handleRequest(event.request)); }); async function handleRequest(request) { // 安全校验 if (request.headers.get(&amp;#39;auth&amp;#39;) !== &amp;#39;auth_code&amp;#39;) { return new Response(&amp;#39;UnAuthorization&amp;#39;, { status: 403 }); } const url = new URL(request.url); url.host = TELEGRAPH_URL.replace(/^https?:\/\//, &amp;#39;&amp;#39;); const modifiedRequest = new Request(url.toString(), { headers: request.headers, method: request.method, body: request.body, redirect: &amp;#39;follow&amp;#39; }); const response = await fetch(modifiedRequest); const modifiedResponse = new Response(response.body, response); // 添加允许跨域访问的响应头 modifiedResponse.</description></item><item><title>数据集</title><link>https://doc.tryfastgpt.ai/docs/development/design/dataset/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/design/dataset/</guid><description>文件与数据的关系 link在 FastGPT 中，文件会通过 MongoDB 的 FS 存储，而具体的数据会通过 PostgreSQL 存储，PG 中的数据会有一列 file_id，关联对应的文件。考虑到旧版本的兼容，以及手动输入、标注数据等，我们给 file_id 增加了一些特殊的值，如下：
manual: 手动输入 mark: 手动标注的数据 注意，file_id 仅在插入数据时会写入，变更时无法修改。
文件导入流程 link 上传文件到 MongoDB 的 FS 中，获取 file_id，此时文件标记为 unused 状态 浏览器解析文件，获取对应的文本和 chunk 给每个 chunk 打上 file_id 点击上传数据：将文件的状态改为 used，并将数据推送到 mongo training 表中等待训练 由训练线程从 mongo 中取数据，并在获取向量后插入到 pg。</description></item><item><title>商业版</title><link>https://doc.tryfastgpt.ai/docs/commercial/intro/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/commercial/intro/</guid><description>简介 linkFastGPT 商业版是基于 FastGPT 开源版的增强版本，增加了一些独有的功能。只需安装一个商业版镜像，并在开源版基础上填写对应的内网地址，即可快速使用商业版。
功能差异 link 开源版 商业版 线上版 应用管理与高级编排 ✅ ✅ ✅ 文档知识库 ✅ ✅ ✅ 外部使用 ✅ ✅ ✅ 最大应用数量 500 无限制 由付费套餐决定 最大知识库数量（单个知识库内容无限制） 30 无限制 由付费套餐决定 自定义版权信息 ❌ ✅ 设计中 多租户与支付 ❌ ✅ ✅ 团队空间 ❌ ✅ ✅ 应用发布安全配置 ❌ ✅ ✅ 内容审核 ❌ ✅ ✅ web站点同步 ❌ ✅ ✅ 管理后台 ❌ ✅ 不需要 增强训练模式 ❌ ✅ ✅ 第三方应用快速接入（飞书、公众号） ❌ ✅ ✅ 图片知识库 ❌ 设计中 设计中 对话日志运营分析 ❌ 设计中 设计中 完整商业授权 ❌ ✅ ✅ 商业版软件价格 linkFastGPT 商业版软件根据不同的部署方式，分为 3 类收费模式。下面列举各种部署方式一些常规内容，如仍有问题，可联系咨询</description></item><item><title>线上版定价</title><link>https://doc.tryfastgpt.ai/docs/pricing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/pricing/</guid><description>线上版价格请查看：https://cloud.fastgpt.in/price</description></item><item><title>开源协议</title><link>https://doc.tryfastgpt.ai/docs/agreement/open-source/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/agreement/open-source/</guid><description>FastGPT 项目在 Apache License 2.0 许可下开源，同时包含以下附加条件：
FastGPT 允许被用于商业化，例如作为其他应用的“后端即服务”使用，或者作为应用开发平台提供给企业。然而，当满足以下条件时，必须联系作者获得商业许可：
多租户 SaaS 服务：除非获得 FastGPT 的明确书面授权，否则不得使用 fastgpt.in 的源码来运营与 fastgpt.in 服务类似的多租户 SaaS 服务。 LOGO 及版权信息：在使用 FastGPT 的过程中，不得移除或修改 FastGPT 控制台内的 LOGO 或版权信息。 请通过电子邮件 yujinlong@sealos.io 联系我们咨询许可事宜。
作为贡献者，你必须同意将你贡献的代码用于以下用途：
生产者有权将开源协议调整为更严格或更宽松的形式。 可用于商业目的，例如 FastGPT 的云服务。 除此之外，所有其他权利和限制均遵循 Apache License 2.0。如果你需要更多详细信息，可以参考 Apache License 2.0 的完整版本。本产品的交互设计受到外观专利保护。© 2023 Sealos.</description></item><item><title>服务协议</title><link>https://doc.tryfastgpt.ai/docs/agreement/terms/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/agreement/terms/</guid><description>最后更新时间：2024年3月3日
FastGPT 服务协议是您与珠海环界云计算有限公司（以下简称“我们”或“本公司”）之间就FastGPT云服务（以下简称“本服务”）的使用等相关事项所订立的协议。请您仔细阅读并充分理解本协议各条款，特别是免除或者限制我们责任的条款、对您权益的限制条款、争议解决和法律适用条款等。如您不同意本协议任一内容，请勿注册或使用本服务。
第1条 服务内容
我们将向您提供存储、计算、网络传输等基于互联网的信息技术服务。 我们将不定期向您通过站内信、电子邮件或短信等形式向您推送最新的动态。 我们将为您提供相关技术支持和客户服务，帮助您更好地使用本服务。 我们将为您提供稳定的在线服务，保证每月服务可用性不低于99%。 第2条 用户注册与账户管理
您在使用本服务前需要注册一个账户。您保证在注册时提供的信息真实、准确、完整，并及时更新。 您应妥善保管账户名和密码，对由此产生的全部行为负责。如发现他人使用您的账户，请及时修改账号密码或与我们进行联系。 我们有权对您的账户进行审查，如发现您的账户存在异常或违法情况，我们有权暂停或终止向您提供服务。 第3条 使用规则
您不得利用本服务从事任何违法活动或侵犯他人合法权益的行为，包括但不限于侵犯知识产权、泄露他人商业机密等。 您不得通过任何手段恶意注册账户，包括但不限于以牟利、炒作、套现等目的。 您不得利用本服务传播任何违法、有害、恶意软件等信息。 您应遵守相关法律法规及本协议的规定，对在本服务中发布的信息及使用本服务所产生的结果承担全部责任。 我们禁止使用我们对接的模型服务生成可能对个人或社会造成伤害的内容。保障平台的安全性，是长期稳定运营的关键。如发现任何利用平台接入模型能力进行违规内容生成和使用，将立即封号，账号余额不退。违规内容包括但不限于： 剥削和虐待 禁止描述、展示或宣扬儿童性剥削或性虐待的内容，无论法律是否禁止。这包括涉及儿童或使儿童色情的内容。 禁止描述或用于培养儿童的内容。修饰是成年人以剥削，特别是性剥削为目的与儿童建立关系的行为。这包括以性剥削、贩运或其他形式剥削为目的与儿童交流。 未经同意的私密内容 服务禁止描述、提供或宣传未经同意的亲密活动的内容。 禁止描述、提供特征或宣传或用于招揽商业性活动和性服务的内容。这包括鼓励和协调真正的性活动。 禁止描述或用于人口贩运目的的内容。这包括招募人员、便利交通、支付和助长对人的剥削，如强迫劳动、家庭奴役、役、强迫婚姻和强迫医疗程序。 自杀和自残，禁止描述、赞美、支持、促进、美化、鼓励和/或指导个人自残或自杀的内容。 暴力内容和行为 禁止描述、展示或宣扬血腥暴力或血腥的内容。 禁止描绘恐怖主义行为的内容；赞扬或支持恐怖组织、恐怖行为者或暴力恐怖意识形态；鼓励恐怖活动；向恐怖组织或恐怖事业提供援助；或协助恐怖组织招募成员。 禁止通过暴力威胁或煽动来鼓吹或宣扬对他人的暴力行为的内容。 仇恨言论和歧视 禁止基于实际或感知的种族、民族、国籍、性别、性别认同、性取向、宗教信仰、年龄、残疾状况、种姓或与系统性偏见或边缘化相关的任何其他特征等特征攻击、诋毁、恐吓、降级、针对或排斥个人或群体的内容。 禁止针对个人或群体进行威胁、恐吓、侮辱、贬低或贬低的语言或图像、宣扬身体伤害或其他虐待行为（如跟踪）的内容。 禁止故意欺骗并可能对公共利益产生不利影响的内容，包括与健康、安全、选举诚信或公民参与相关的欺骗性或不真实内容。 直接支持非法主动攻击或造成技术危害的恶意软件活动的内容，例如提供恶意可执行文件、组织拒绝服务攻击或管理命令和控制服务器。 第4条 费用及支付
您同意支付与本服务相关的费用，具体费用标准以我们公布的价格为准。 我们可能会根据运营成本和市场情况调整费用标准。最新价格以您付款时刻的价格为准。 第5条 服务免责与责任限制
本服务按照现有技术和条件所能达到的水平提供。我们不能保证本服务完全无故障或满足您的所有需求。 对于因您自身误操作导致的数据丢失、损坏等情况，我们不承担责任。 由于生成式 AI 的特性，其在不同国家的管控措施也会有所不同，请所有使用者务必遵守所在地的相关法律。如果您以任何违反 FastGPT 可接受使用政策的方式使用，包括但不限于法律、法规、政府命令或法令禁止的任何用途，或任何侵犯他人权利的使用；由使用者自行承担。我们对由客户使用产生的问题概不负责。下面是各国对生成式AI的管控条例的链接： 中国生成式人工智能服务管理办法（征求意见稿）
第6条 知识产权
我们对本服务及相关软件、技术、文档等拥有全部知识产权，除非经我们明确许可，您不得进行复制、分发、出租、反向工程等行为。 您在使用本服务过程中产生的所有数据和内容（包括但不限于文件、图片等）的知识产权归您所有。我们不会对您的数据和内容进行使用、复制、修改等行为。 在线服务中其他用户的数据和内容的知识产权归原用户所有，未经原用户许可，您不得进行使用、复制、修改等行为。 第7条 其他条款
如本协议中部分条款因违反法律法规而被视为无效，不影响其他条款的效力。 本公司保留对本协议及隐私政策的最终解释权。如您对本协议或隐私政策有任何疑问，请联系我们：yujinlong@sealos.io。</description></item><item><title>隐私政策</title><link>https://doc.tryfastgpt.ai/docs/agreement/privacy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/agreement/privacy/</guid><description>最后更新时间：2024年3月3日
我们非常重视您的隐私保护，在您使用FastGPT云服务时(以下简称为“本服务”)，我们将按照以下政策收集、使用、披露和保护您的个人信息。请您仔细阅读并充分理解本隐私政策。
我们可能需要收集的信息
在您注册或使用本服务时，我们可能收集您的姓名、电话号码、电子邮件地址、地址等个人信息。 在您使用本服务过程中产生的信息，如操作日志、访问IP地址、设备型号等。 我们可能会通过 Cookies 或其他技术收集和存储您访问本服务的相关信息，以便为您提供更好的用户体验。 我们如何使用收集的信息？
我们会根据法律法规规定以及与用户之间的约定来处理用户的个人信息。 我们可能会将收集到的信息用于改进服务质量、开发新产品或功能等目的。 我们可能会将收集到的信息用于向您推送与本服务相关的通知或广告。 信息披露
我们不会向任何第三方披露您的个人信息，除非：
您事先同意； 法律法规要求； 为维护我们或其他用户的合法权益。 我们可能与关联公司、合作伙伴分享您的个人信息，但我们会采取相应的保密措施，确保信息安全。
信息保护
我们采取各种安全措施，包括加密、访问控制等技术手段，以保护您的个人信息免受未经授权的访问、使用或泄露。 我们会定期对收集、存储和处理的个人信息进行安全评估，以确保个人信息安全。 在发生个人信息泄露等安全事件时，我们会立即启动应急预案，并在法律法规规定的范围内向您及时告知。 我们不会使用您的数据进行额外的备份存储或用于模型训练。 您在本服务进行的数据删除均为物理删除，不可恢复。如有非物理删除的操作，我们会在服务中特别指出。 用户权利
您有权随时查阅、更正或删除您的个人信息。 您有权拒绝我们收集您的个人信息，但这可能导致您无法使用本服务的部分功能。 您有权要求我们停止处理您的个人信息，但这可能导致您无法继续使用本服务。 隐私政策更新
我们可能会对本隐私政策进行修改。如本隐私政策发生变更，我们将在本服务页面上发布修改后的隐私政策。如您继续使用本服务，则视为同意修改后的隐私政策。 我们鼓励您定期查阅本隐私政策，以了解我们如何保护您的个人信息。 未成年人保护
我们非常重视对未成年人个人信息的保护，如您为未成年人，请在监护人指导下使用本服务，并请监护人帮助您在使用本服务过程中正确处理个人信息。
跨境数据传输
由于我们的服务器可能位于不同国家或地区，您同意我们可能需要将您的个人信息传输至其他国家或地区，并在该等国家或地区存储和处理以向您提供服务。我们会采取适当措施确保跨境传输的数据仍然受到适当保护。
联系我们
如您对本隐私政策有任何疑问、建议或投诉，请通过以下方式与我们联系：yujinlong@sealos.io。 我们将尽快回复并解决您提出的问题。</description></item><item><title>加入社区</title><link>https://doc.tryfastgpt.ai/docs/community/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/community/</guid><description>FastGPT 是一个由用户和贡献者参与推动的开源项目，如果您对产品使用存在疑问和建议，可尝试以下方式寻求支持。我们的团队与社区会竭尽所能为您提供帮助。
📱 扫码加入社区微信交流群👇
🐞 请将任何 FastGPT 的 Bug、问题和需求提交到 GitHub Issue。</description></item></channel></rss>